# Data Science, Machine Learning &amp; Deep Learning

## Topics

1. Statistical Modeling
2. Hypothesis Testing
3. Data Analysis
4. Algorithms
5. Building models
6. 


### Libraries 
---
<b>Essentials</b>
* pandas
* numpy
* scipy
* sklearn
* statsmodels
* linearmodels
* pickle
* category_encoders
* xgboost
* lightgbm
* multiprocessing
* imblearn
* umap
* hyperopt
* 

---
<b>Plots</b>
* matplotlib
* seaborn
* pylab
* mglearn
* graphviz
* plotly
* mpl_toolkits
* 

---
<b>Python</b>
* collections
* itertools
* datetime
* random
* time
* ast
* csv
* json
* subprocess
* threading
* functools
* 

<b>Text processing</b>
* nltk
* gensim
* tweepy
* 
---
<b>Code review</b>
* pytest
* pylint
* cProfile
* pstats
* pdb
* logger
* 
---
<b>Miscellaneous</b>
* os
* gc
* sys
* glob
* ctypes
* psutil
* tkinter
* inspect
* builtins
* zipfile36
* warnings
* missingno
* 

---

#### sklearn
  - svm
  - tree
  - utils
  - metrics
    - recall_score
    - accuracy_score
    - confusion_matrix
    - scorer.make_scorer
    - classification_report
    - 
  - decomposition
    - PCA
    - FastICA
    - 
  - pipeline
    - Pipeline
  - datasets
  - manifold
  - ensemble
    - RandomForestClassifier
  - neighbors
    - NearestNeighbors
    - nearest_centroid.NearestCentroid
    - KNeighborsClassifier
    - 
  - covariance
  - naive_bayes
    - GaussianNB
  - linear_model
    - Ridge
    - Lasso
    - RidgeCV
    - BayesianRidge
    - LinearRegression
    - LogisticRegression
    - LogisticRegressionCV
    - RidgeClassifierCV
    - RidgeClassifier
    - SGDClassifier
    - 
  - preprocessing
    - Imputer
    - MinMaxScaler
    - StandardScaler
    - 
  - model_selection
    - KFold
    - StratifiedKFold
    - GridSearchCV
    - cross_validate
    - cross_val_score
    - cross_val_predict
    - train_test_split
    - 
  - feature_selection
    - f_classif
    - SelectKBest
    - SelectFromModel
    - VarianceThreshold
    - 
  - exceptions
    - ConvergenceWarning
    - 
  - discriminant_analysis
    - LinearDiscriminantAnalysis
    - QuadraticDiscriminantAnalysis
    - 
  - neural_network
  - kernel_ridge
    - KernelRidge
    - 
  
### Algorithms

Based on...

#### Bayesian Methods
  - <i>for classification and regression problems; probability model</i>
  - Naive Bayes
  - Bayesian Belief Network

#### Clustering Methods
  - K-Means
  - Expectation Maximization
  - Gaussian Mixture Models (GMM)
  - Mean Shift
  - Agglomerative /Heirarchical
  
#### Decision Tree 
  - <i>for classification and regression problems</i>
  - Random forest
  - Classification and Regression Tree (CART)
  - C4.5 and C5.0
  - Gradient boosting machines (GBM)
  - Decision stump
  - Multivariate adaptive regression splines (MARS)
  - Chi-square, Chi-Squared Automatic Interaction Detection (CHAID)

#### Ensemble Methods
  - AdaBoost
  - Bagging
  - Blending (Stacked generalization)
  - Boosting (Bootstrapped Aggregation)
  - Gradient Boosting Machine
  - Random Forest
  - 

#### Instance 
  - k-NN
  - Learning Vector Quantization
  - 
  
#### Kernel Methods
  - <i>geometric model</i>
  - SVM
  - LDA

#### Regression 
  - Linear Regression
    - OLS, Penalized Ridge, Lasso
  - Logistic Regression
  - Multivariate adaptive regression splines (MARS)
  - Stepwise Regression

![alt text](https://s3.amazonaws.com/MLMastery/MachineLearningAlgorithms.png?__s=cfxyzoumz2rsxq8s1qwd)

Image credits: <i> Jason @ ML Mastery jason@machinelearningmastery.com </i>

---

Creation Date: 31/05/2018 <br/>
Created By: Praveen T N <br/>
Reach Out: @iVanPeer <br/>

#### Trivia
---
<i>laxism</i>: a viewpoint in the probabilistic controversy that in a conflict between liberty and law a slightly probable argument for liberty suffices to furnish a basis for action

<i>probabilism</i>: a theory that certainty is impossible especially in the sciences and that probability suffices to govern belief and action

#### Philosopher's beans
<i>Few beans of this handful are white <br/>
  Most beans in this bag are white <br/>
  Therefore, probably these beans were taken from another bag <br/>
  This is an hypothetical inference!</i>
