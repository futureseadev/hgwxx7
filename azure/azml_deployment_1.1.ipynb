{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from azureml.core import Workspace, Experiment, Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(path=\"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = read_csv(url, names=names)\n",
    "\n",
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "model = SVC(gamma='auto')\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'models/finalized_iris_model_new.sav'\n",
    "joblib.dump(model, open(filename, 'wb'))\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Register model\n",
    "model = Model.register(workspace = ws,\n",
    "                        model_path=filename,\n",
    "                        model_name = \"iris_model_new\",\n",
    "                        tags = {\"ziris\": \"demo\"},\n",
    "                        description = \"Iris Model Zoo\",)\n",
    "\n",
    "print(model.name, model.id, model.version, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [[5.7, 3.9, 1.1, 0.1]]\n",
    "Y_test = ['Iris-setosa']\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)\n",
    "\n",
    "loaded_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice, AksWebservice, LocalWebservice\n",
    "\n",
    "# set environment name\n",
    "env_name = \"envxyz\"\n",
    "env = Environment.get(ws, \"AzureML-Minimal\").clone(env_name)\n",
    "\n",
    "for pip_package in [\"scikit-learn\",]:\n",
    "    env.python.conda_dependencies.add_pip_package(pip_package)\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score.py',\n",
    "                                    environment=env)\n",
    "\n",
    "service_name = 'tirisservice'\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1,)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                      name=service_name,\n",
    "                      models=[model],\n",
    "                      inference_config=inference_config,\n",
    "                      deployment_config=aci_config,\n",
    "                      overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)\n",
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "X_test = [[5.7, 3.9, 1.1, 0.1]]\n",
    "Y_test = ['Iris-setosa']\n",
    "\n",
    "# URL for the web service\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "key = None\n",
    "\n",
    "# Two sets of data to score, so we get two results back\n",
    "data = {\n",
    "        \"data\": X_test\n",
    "       }\n",
    "\n",
    "# Convert to JSON string\n",
    "input_data = json.dumps(data)\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "#headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
