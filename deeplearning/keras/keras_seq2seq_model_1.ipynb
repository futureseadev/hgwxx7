{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence 2 Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://towardsdatascience.com/solving-nlp-task-using-sequence2sequence-model-from-zero-to-hero-c193c1bd03d1\n",
    "### https://github.com/shudima/notebooks/blob/master/NER.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    basestring\n",
    "except NameError:\n",
    "    basestring = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df = pd.read_csv('ner_dataset_min.csv', encoding=\"ISO-8859-1\")\n",
    "#ner_df['Word'] = ner_df['Word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>war</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demand</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>troops</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>country</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #           Word  POS    Tag\n",
       "0   Sentence: 1      Thousands  NNS      O\n",
       "1           NaN             of   IN      O\n",
       "2           NaN  demonstrators  NNS      O\n",
       "3           NaN           have  VBP      O\n",
       "4           NaN        marched  VBN      O\n",
       "5           NaN        through   IN      O\n",
       "6           NaN         London  NNP  B-geo\n",
       "7           NaN             to   TO      O\n",
       "8           NaN        protest   VB      O\n",
       "9           NaN            the   DT      O\n",
       "10          NaN            war   NN      O\n",
       "11          NaN             in   IN      O\n",
       "12          NaN           Iraq  NNP  B-geo\n",
       "13          NaN            and   CC      O\n",
       "14          NaN         demand   VB      O\n",
       "15          NaN            the   DT      O\n",
       "16          NaN     withdrawal   NN      O\n",
       "17          NaN             of   IN      O\n",
       "18          NaN        British   JJ  B-gpe\n",
       "19          NaN         troops  NNS      O\n",
       "20          NaN           from   IN      O\n",
       "21          NaN           that   DT      O\n",
       "22          NaN        country   NN      O\n",
       "23          NaN              .    .      O\n",
       "24  Sentence: 2       Families  NNS      O\n",
       "25          NaN             of   IN      O\n",
       "26          NaN       soldiers  NNS      O\n",
       "27          NaN         killed  VBN      O\n",
       "28          NaN             in   IN      O\n",
       "29          NaN            the   DT      O"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1280)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_words = []\n",
    "sentences_tags = []\n",
    "curr_sent_num = -1\n",
    "current_sentence_words = []\n",
    "current_sentence_tags = []\n",
    "for sent_num, word, tag in ner_df[['Sentence #', 'Word', 'Tag']].values:   \n",
    "    if isinstance(sent_num, basestring) and 'Sentence: ' in sent_num:\n",
    "        curr_sent_num = int(sent_num.split(':')[1].strip())\n",
    "        \n",
    "        if current_sentence_words and current_sentence_tags:\n",
    "            sentences_words.append(current_sentence_words)\n",
    "            sentences_tags.append(current_sentence_tags)\n",
    "            \n",
    "        current_sentence_words = []\n",
    "        current_sentence_tags = []\n",
    "    \n",
    "    current_sentence_words.append(word.encode(encoding='ISO-8859-1', ).decode(errors='replace'))\n",
    "    current_sentence_tags.append(tag)\n",
    "\n",
    "len(sentences_words), len(sentences_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not O\n",
      "counting O\n",
      "the O\n",
      "latest O\n",
      "death O\n",
      ", O\n",
      "the O\n",
      "World B-org\n",
      "Health I-org\n",
      "Organization I-org\n",
      "says O\n",
      "227 O\n",
      "people O\n",
      "around O\n",
      "the O\n",
      "world O\n",
      "have O\n",
      "died O\n",
      "from O\n",
      "bird O\n",
      "flu O\n",
      "since O\n",
      "2003 B-tim\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "for w, k in zip(sentences_words[123], sentences_tags[123]):\n",
    "    print(w, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1024 1024\n",
      "Test: 256 256\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(sentences_words) * 0.8)\n",
    "\n",
    "train_sentences_words = sentences_words[:train_size]\n",
    "train_sentences_tags = sentences_tags[:train_size]\n",
    "test_sentences_words = sentences_words[train_size:]\n",
    "test_sentences_tags = sentences_tags[train_size:]\n",
    "\n",
    "print('Train:', len(train_sentences_words), len(train_sentences_tags))\n",
    "print('Test:', len(test_sentences_words), len(test_sentences_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW + Cls Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_instances(words, tags, bow, count_vectorizer):\n",
    "    X = []\n",
    "    y = []\n",
    "    for w, t in zip(words, tags):\n",
    "        v = count_vectorizer.transform([w])[0]\n",
    "        v = scipy.sparse.hstack([v, bow])\n",
    "        X.append(v)\n",
    "        y.append(t)\n",
    "        \n",
    "    return scipy.sparse.vstack(X), y\n",
    "\n",
    "def sentences_to_instances(sentences_words, sentences_tags, count_vectorizer):\n",
    "    bows = count_vectorizer.transform(map(lambda s: ' '.join(s), sentences_words))\n",
    "    X = []\n",
    "    y = []\n",
    "    for words, tags, bow in zip(sentences_words, sentences_tags, bows):\n",
    "        sent_X, sent_y = sentence_to_instances(words, tags, bow, count_vectorizer)\n",
    "        X.append(sent_X)\n",
    "        y += sent_y\n",
    "        \n",
    "    return scipy.sparse.vstack(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype='int32', encoding='utf-8', input='content', lowercase=True,\n",
       "        max_df=1.0, max_features=None, min_df=1, ngram_range=(1, 1),\n",
       "        preprocessor=None, stop_words=None, strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(dtype='int32').fit(map(lambda s: ' '.join(s), train_sentences_words))\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%time train_X, train_y = sentences_to_instances(train_sentences_words, train_sentences_tags, count_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22616, 8576), (22616,))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%time test_X, test_y = sentences_to_instances(test_sentences_words, test_sentences_tags, count_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5858, 8576), (5858,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Continuum\\anaconda3\\envs\\crtasks\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Continuum\\anaconda3\\envs\\crtasks\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         5\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.90      0.28      0.43       186\n",
      "       B-gpe       0.66      0.74      0.70        85\n",
      "       B-nat       0.00      0.00      0.00         3\n",
      "       B-org       0.73      0.25      0.37       145\n",
      "       B-per       0.78      0.30      0.43        93\n",
      "       B-tim       0.86      0.59      0.70       111\n",
      "       I-art       0.00      0.00      0.00         3\n",
      "       I-eve       0.00      0.00      0.00         0\n",
      "       I-geo       0.31      0.24      0.27        33\n",
      "       I-gpe       0.00      0.00      0.00         1\n",
      "       I-nat       0.00      0.00      0.00         2\n",
      "       I-org       0.59      0.32      0.42        69\n",
      "       I-per       0.69      0.20      0.31        89\n",
      "       I-tim       0.11      0.03      0.04        38\n",
      "           O       0.91      0.99      0.95      4995\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      5858\n",
      "   macro avg       0.38      0.23      0.27      5858\n",
      "weighted avg       0.88      0.90      0.87      5858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nearby',\n",
       " 'pardons',\n",
       " 'stay',\n",
       " 'Recalled',\n",
       " 'point',\n",
       " 'Prosecutors',\n",
       " '2017',\n",
       " 'hour-long',\n",
       " 'cities',\n",
       " 'Anne-Marie',\n",
       " 'demonstration',\n",
       " 'Irbil',\n",
       " 'Warner',\n",
       " 'supposed',\n",
       " 'trying',\n",
       " 'Inspector',\n",
       " 'strategies',\n",
       " 'After',\n",
       " 'crime',\n",
       " 'difficulty',\n",
       " 'Anbar',\n",
       " 'Warri',\n",
       " 'rolling',\n",
       " 'uncovered',\n",
       " 'hospitalization',\n",
       " 'returned',\n",
       " 'Ron',\n",
       " 'poorest',\n",
       " 'mortar',\n",
       " 'export',\n",
       " 'extending',\n",
       " 'daughter',\n",
       " 'closed',\n",
       " 'grave',\n",
       " 'contractors',\n",
       " 'Sharon',\n",
       " 'deadliness',\n",
       " 'protest',\n",
       " 'both',\n",
       " 'outlets',\n",
       " 'Lithuania',\n",
       " '38-year-old',\n",
       " 'practitioners',\n",
       " 'social',\n",
       " 'Roche',\n",
       " 'delegation',\n",
       " 'her',\n",
       " 'Professionals',\n",
       " 'Egyptian-born',\n",
       " 'airlines',\n",
       " 'Fatah',\n",
       " 'Swazis',\n",
       " 'special',\n",
       " 'managers',\n",
       " 'Indonesian',\n",
       " 'overflowed',\n",
       " 'live',\n",
       " 'Bangladesh',\n",
       " 'flood',\n",
       " 'Rica',\n",
       " 'marred',\n",
       " 'ready',\n",
       " 'capital',\n",
       " 'stress',\n",
       " 'Collemaggio',\n",
       " 'environment',\n",
       " 'sentence',\n",
       " 'livestock',\n",
       " 'abating',\n",
       " 'Philip',\n",
       " 'HMS',\n",
       " 'director',\n",
       " 'coordinated',\n",
       " 'commented',\n",
       " 'Latvia',\n",
       " 'refer',\n",
       " 'colonized',\n",
       " 'stone',\n",
       " 'blast',\n",
       " 'need',\n",
       " 'Hezbollah',\n",
       " 'comparing',\n",
       " 'death',\n",
       " 'deadly',\n",
       " 'embassies',\n",
       " 'presence',\n",
       " 'If',\n",
       " 'ran',\n",
       " 'uncertain',\n",
       " 'democratic',\n",
       " 'bars',\n",
       " 'Democratic',\n",
       " 'candidate',\n",
       " 'Ahmadinejad',\n",
       " 'intercontinental',\n",
       " 'valley',\n",
       " 'linked',\n",
       " 'which',\n",
       " 'several',\n",
       " 'judge',\n",
       " 'officers',\n",
       " 'barrels',\n",
       " 'assistance',\n",
       " 'doubled',\n",
       " 'distraction',\n",
       " 'so',\n",
       " 'hemisphere',\n",
       " 'picked',\n",
       " 'speaks',\n",
       " 'Association',\n",
       " 'Simple',\n",
       " '$',\n",
       " 'stronghold',\n",
       " 'together',\n",
       " 'bin',\n",
       " 'Thaksin',\n",
       " 'northeast',\n",
       " 'treaty',\n",
       " 'lines',\n",
       " 'repeatedly',\n",
       " 'thanked',\n",
       " 'Deputy',\n",
       " 'prisoners',\n",
       " 'hall',\n",
       " 'concluding',\n",
       " 'Lebanon',\n",
       " 'seeking',\n",
       " 'chart',\n",
       " 'riches',\n",
       " 'at',\n",
       " 'arrived',\n",
       " 'food',\n",
       " 'among',\n",
       " 'cap',\n",
       " 'window',\n",
       " 'wrong',\n",
       " 'exchange',\n",
       " 'message',\n",
       " '1910',\n",
       " 'snowed',\n",
       " 'Sri',\n",
       " 'caucuses',\n",
       " 'laborers',\n",
       " 'excessively',\n",
       " 'foreigners',\n",
       " 'strongly',\n",
       " 'keep',\n",
       " 'plea',\n",
       " 'Science',\n",
       " 'Classic',\n",
       " 'ties',\n",
       " 'remote-controlled',\n",
       " 'shortage',\n",
       " 'desperate',\n",
       " 'controls',\n",
       " 'determined',\n",
       " 'senior',\n",
       " 'parliament',\n",
       " 'evidence',\n",
       " 'tested',\n",
       " 'passage',\n",
       " 'religion',\n",
       " 'believe',\n",
       " 'witnesses',\n",
       " 'construction',\n",
       " 'cheated',\n",
       " 'Amy',\n",
       " 'instability',\n",
       " 'rein',\n",
       " 'strangers',\n",
       " 'prosecuting',\n",
       " 'Moscow',\n",
       " 'Argentina',\n",
       " 'complex',\n",
       " '80-year-old',\n",
       " 'spared',\n",
       " 'charge',\n",
       " 'anger',\n",
       " 'presented',\n",
       " 'society',\n",
       " 'we',\n",
       " 'fair',\n",
       " 'needed',\n",
       " 'Omar',\n",
       " 'Muhammad',\n",
       " 'Japanese',\n",
       " 'counting',\n",
       " 'severity',\n",
       " 'captivity',\n",
       " 'uncertainty',\n",
       " '12-year-old',\n",
       " 'Uganda',\n",
       " 'Court',\n",
       " 'ship',\n",
       " 'Atwah',\n",
       " 'irrationality',\n",
       " 'charities',\n",
       " 'surgeries',\n",
       " 'and',\n",
       " 'stormed',\n",
       " 'Museveni',\n",
       " 'massacre',\n",
       " '300',\n",
       " 'Muslims',\n",
       " 'Residents',\n",
       " 'slaughtering',\n",
       " 'debate',\n",
       " 'subsequently',\n",
       " '27',\n",
       " 'Condoleezza',\n",
       " '12',\n",
       " 'cautious',\n",
       " 'smuggling',\n",
       " 'May',\n",
       " 'cancer',\n",
       " 'impose',\n",
       " 'leveled',\n",
       " 'freezing',\n",
       " 'sections',\n",
       " 'Authorities',\n",
       " 'flee',\n",
       " 'remnants',\n",
       " 'actions',\n",
       " 'gathered',\n",
       " '150',\n",
       " 'wind-blown',\n",
       " 'member',\n",
       " 'polluted',\n",
       " 'resign',\n",
       " 'language',\n",
       " 'John',\n",
       " 'midnight',\n",
       " 'Thai',\n",
       " 'head',\n",
       " 'Egypt',\n",
       " '06-Mar',\n",
       " 'Bayelsa',\n",
       " 'moved',\n",
       " 'expressed',\n",
       " 'injuring',\n",
       " 'Aid',\n",
       " 'Huygens',\n",
       " 'Laden',\n",
       " 'bakery',\n",
       " 'moderate',\n",
       " 'Tasnim',\n",
       " 'responsibility',\n",
       " 'planes',\n",
       " 'Bob',\n",
       " 'fiscal',\n",
       " 'crimes',\n",
       " 'aides',\n",
       " 'slowed',\n",
       " 'Celsius',\n",
       " 'Bhumibol',\n",
       " 'disaster',\n",
       " 'Following',\n",
       " 'happen',\n",
       " 'Lawrence',\n",
       " 'Russians',\n",
       " 'animals',\n",
       " 'interim',\n",
       " 'tense',\n",
       " 'reviewed',\n",
       " 'east',\n",
       " 'abducted',\n",
       " 'problematic',\n",
       " 'diseases',\n",
       " '?',\n",
       " 'undocumented',\n",
       " 'invited',\n",
       " 'describes',\n",
       " 'values',\n",
       " 'street',\n",
       " 'reduction',\n",
       " 'law',\n",
       " 'dealing',\n",
       " 'Guinea',\n",
       " 'regulators',\n",
       " 'Hague',\n",
       " 'jobless',\n",
       " 'graves',\n",
       " 'cause',\n",
       " 'semifinals',\n",
       " 'Regular',\n",
       " 'rock',\n",
       " 'Santos',\n",
       " 'declaration',\n",
       " 'stepped',\n",
       " 'self-imposed',\n",
       " 'delayed',\n",
       " 'postal',\n",
       " 'The',\n",
       " 'pretty',\n",
       " 'nutrient',\n",
       " 'noting',\n",
       " 'sides',\n",
       " 'Island',\n",
       " 'two-day',\n",
       " 'strategic',\n",
       " 'Abramoff',\n",
       " 'Israelis',\n",
       " 'islands',\n",
       " 'secretary',\n",
       " 'Hugo',\n",
       " 'Thailand',\n",
       " 'ongoing',\n",
       " 'prize',\n",
       " 'investigate',\n",
       " 'Summer',\n",
       " 'been',\n",
       " 'ridding',\n",
       " 'Kenya',\n",
       " 'how',\n",
       " 'emerged',\n",
       " 'authority',\n",
       " 'Jihad',\n",
       " 'cellist',\n",
       " 'Tehran',\n",
       " 'resumption',\n",
       " 'remarks',\n",
       " 'Hushiar',\n",
       " 'Syrian',\n",
       " 'November',\n",
       " 'respects',\n",
       " 'factions',\n",
       " 'advised',\n",
       " 'suburb',\n",
       " 'build',\n",
       " 'Georgians',\n",
       " 'abundantly',\n",
       " 'loyal',\n",
       " 'funeral',\n",
       " 'children',\n",
       " 'Helmand',\n",
       " 'closer',\n",
       " 'Washington-based',\n",
       " 'stationary',\n",
       " 'panels',\n",
       " 'Admiral',\n",
       " 'King',\n",
       " 'effort',\n",
       " 'pervasive',\n",
       " 'Haitian',\n",
       " 'goal',\n",
       " 'landmine',\n",
       " 'Salvatrucha',\n",
       " 'used',\n",
       " 'Terrorist',\n",
       " 'Age',\n",
       " 'auditors',\n",
       " 'commission',\n",
       " 'Khartoum',\n",
       " 'dormitory',\n",
       " 'temperatures',\n",
       " 'proposals',\n",
       " 'operative',\n",
       " 'Elsewhere',\n",
       " 'addition',\n",
       " 'industries',\n",
       " 'Chairman',\n",
       " 'registered',\n",
       " 'Humans',\n",
       " 'unearthed',\n",
       " 'there',\n",
       " 'fall',\n",
       " 'bit',\n",
       " 'shows',\n",
       " 'cooperate',\n",
       " 'Guard',\n",
       " 'finalize',\n",
       " 'annual',\n",
       " 'forgiving',\n",
       " 'operating',\n",
       " 'overflowing',\n",
       " 'works',\n",
       " 'convicted',\n",
       " 'Ocean',\n",
       " 'recipients',\n",
       " 'orphaned',\n",
       " 'Rebels',\n",
       " 'divided',\n",
       " 'Separately',\n",
       " 'drugs',\n",
       " 'Lebanese',\n",
       " '7',\n",
       " 'Arak',\n",
       " 'facility',\n",
       " 'secure',\n",
       " 'typical',\n",
       " 'Vahidi',\n",
       " 'Redmond',\n",
       " 'stimulated',\n",
       " 'visited',\n",
       " 'French',\n",
       " 'claiming',\n",
       " 'hideout',\n",
       " 'document',\n",
       " 'mainly',\n",
       " 'Norway',\n",
       " 'earmarked',\n",
       " 'Herbert',\n",
       " 'hoping',\n",
       " 'regional',\n",
       " 'mend',\n",
       " 'archaeological',\n",
       " 'Independence',\n",
       " '4.5',\n",
       " 'resulting',\n",
       " 'oversees',\n",
       " 'al-Maliki',\n",
       " 'evil',\n",
       " 'places',\n",
       " 'letting',\n",
       " 'word',\n",
       " 'hideouts',\n",
       " 'treasures',\n",
       " 'scientist',\n",
       " 'budget',\n",
       " 'ended',\n",
       " 'kids',\n",
       " 'printing',\n",
       " 'seven',\n",
       " 'Sydney',\n",
       " 'bus',\n",
       " 'sentenced',\n",
       " 'Benjamin',\n",
       " 'Smaller',\n",
       " 'disgraced',\n",
       " 'confirm',\n",
       " 'treat',\n",
       " 'Regina',\n",
       " 'visa',\n",
       " 'combining',\n",
       " 'unbeatable',\n",
       " 'efficiency',\n",
       " 'spent',\n",
       " 'Kooyong',\n",
       " 'deluge',\n",
       " 'operations',\n",
       " 'predicted',\n",
       " 'Wael',\n",
       " 'contributions',\n",
       " 'stability',\n",
       " 'flared',\n",
       " 'combination',\n",
       " 'season',\n",
       " 'breakup',\n",
       " 'Adil',\n",
       " 'Jose',\n",
       " 'eligible',\n",
       " 'Yemen',\n",
       " 'ambushes',\n",
       " 'hope',\n",
       " 'Non-Proliferation',\n",
       " 'order',\n",
       " '1',\n",
       " 'inspectors',\n",
       " 'details',\n",
       " 'things',\n",
       " 'mine',\n",
       " 'despite',\n",
       " 'as',\n",
       " 'charging',\n",
       " 'Hussain',\n",
       " 'participate',\n",
       " 'deplored',\n",
       " '5.8',\n",
       " 'Fujimori',\n",
       " 'mourn',\n",
       " 'activist',\n",
       " 'reversed',\n",
       " 'sandstorm',\n",
       " 'taunted',\n",
       " 'thousands',\n",
       " 'United',\n",
       " '439',\n",
       " 'lavish',\n",
       " 'Sisco',\n",
       " 'advising',\n",
       " 'Mullen',\n",
       " 'Radical',\n",
       " 'large',\n",
       " 'economy',\n",
       " 'Rangoon',\n",
       " 'ex-chancellor',\n",
       " 'sector',\n",
       " 'Student',\n",
       " 'offered',\n",
       " 'deeply',\n",
       " '32-year-old',\n",
       " 'decided',\n",
       " 'resignation',\n",
       " 'Interviewed',\n",
       " 'eliminate',\n",
       " 'observed',\n",
       " 'port',\n",
       " 'allegedly',\n",
       " 'break',\n",
       " 'Ghana',\n",
       " 'canceled',\n",
       " 'preach',\n",
       " 'Contreras',\n",
       " 'inundated',\n",
       " 'jury',\n",
       " 'fraud',\n",
       " 'processing',\n",
       " 'self-rule',\n",
       " 'conductor',\n",
       " 'leaders',\n",
       " 'reunifying',\n",
       " 'south',\n",
       " 'concerns',\n",
       " 'Chinese',\n",
       " 'chance',\n",
       " 'meals',\n",
       " 'already',\n",
       " 'treatment',\n",
       " 'demands',\n",
       " '2006',\n",
       " 'comes',\n",
       " 'Popular',\n",
       " 'Akmatbayev',\n",
       " 'possible',\n",
       " 'miners',\n",
       " 'peaceful',\n",
       " 'Congress',\n",
       " '--',\n",
       " 'identified',\n",
       " 'Pyongyang',\n",
       " 'incurable',\n",
       " 'Guillermo',\n",
       " 'rescue',\n",
       " 'Uruguay',\n",
       " 'communities',\n",
       " '18',\n",
       " 'Adnan',\n",
       " 'total',\n",
       " 'verbally',\n",
       " 'local',\n",
       " 'Karzai',\n",
       " 'operate',\n",
       " 'unthinkable',\n",
       " 'Australia',\n",
       " '13',\n",
       " 'retirement',\n",
       " 'congressional',\n",
       " 'find',\n",
       " 'Athens',\n",
       " 'During',\n",
       " 'Colombian',\n",
       " 'frequently',\n",
       " 'Medusa',\n",
       " 'hidden',\n",
       " 'share',\n",
       " 'Martyrs',\n",
       " 'cooperation',\n",
       " 'Saadoun',\n",
       " 'Mikhail',\n",
       " 'now',\n",
       " 'Several',\n",
       " '2000',\n",
       " 'wounds',\n",
       " '80',\n",
       " 'medal',\n",
       " 'public',\n",
       " 'occur',\n",
       " 'associate',\n",
       " 'he',\n",
       " 'protectionist',\n",
       " 'relaxing',\n",
       " 'cigarette',\n",
       " 'symbolize',\n",
       " 'Sudanese',\n",
       " 'abuse',\n",
       " 'collapse',\n",
       " 'pardoning',\n",
       " 'intoxicated',\n",
       " 'established',\n",
       " 'sailed',\n",
       " 'Luiz',\n",
       " 'Human',\n",
       " 'Medical',\n",
       " 'die',\n",
       " 'suspects',\n",
       " 'address',\n",
       " 'Ashibli',\n",
       " 'training',\n",
       " 'diplomats',\n",
       " 'migrants',\n",
       " 'images',\n",
       " 'late',\n",
       " 'appointee',\n",
       " 'based',\n",
       " 'broken',\n",
       " 'backyard',\n",
       " 'Younis',\n",
       " 'Police',\n",
       " 'come',\n",
       " 'lower',\n",
       " 'turban',\n",
       " 'becoming',\n",
       " 'reward',\n",
       " 'quake',\n",
       " 'Serbs',\n",
       " 'lobbyist',\n",
       " 'altar',\n",
       " 'Cuban',\n",
       " 'killed',\n",
       " 'straight-sets',\n",
       " 'users',\n",
       " 'Martin',\n",
       " 'shooting',\n",
       " 'him',\n",
       " 'compete',\n",
       " 'speech',\n",
       " 'terrorists',\n",
       " 'whether',\n",
       " 'invest',\n",
       " 'Good',\n",
       " 'wave',\n",
       " 'demonstrated',\n",
       " 'although',\n",
       " 'chosen',\n",
       " 'Mozambique',\n",
       " 'ruin',\n",
       " 'ones',\n",
       " 'urban',\n",
       " 'accord',\n",
       " 'drag',\n",
       " 'preventing',\n",
       " 'agreement',\n",
       " 'al-Sadr',\n",
       " 'initial',\n",
       " 'regarded',\n",
       " 'infected',\n",
       " 'Meantime',\n",
       " 'Iranian',\n",
       " 'occurred',\n",
       " 'bombs',\n",
       " 'usual',\n",
       " 'right',\n",
       " 'motive',\n",
       " 'IAEA',\n",
       " 'Mr.',\n",
       " 'quarterly',\n",
       " 'for',\n",
       " 'Five',\n",
       " 'Christmas',\n",
       " 'months',\n",
       " 'driving',\n",
       " '\"',\n",
       " 'Adam',\n",
       " 'commissioning',\n",
       " 'staff',\n",
       " 'deal',\n",
       " 'greater',\n",
       " 'others',\n",
       " 'Yass',\n",
       " 'Xavier',\n",
       " 'Harcourt',\n",
       " 'profitable',\n",
       " '2.3',\n",
       " '1834',\n",
       " 'Carlos',\n",
       " 'Tikrit',\n",
       " 'al',\n",
       " 'proximity',\n",
       " 'relatively',\n",
       " 'friends',\n",
       " '77-year-old',\n",
       " 'transportation',\n",
       " 'ice',\n",
       " 'fled',\n",
       " 'through',\n",
       " 'Ahmad',\n",
       " 'Mireya',\n",
       " 'odds',\n",
       " 'Katutsi',\n",
       " 'Bosnia-Herzegovina',\n",
       " 'my',\n",
       " 'Malaysian',\n",
       " 'motivated',\n",
       " 'This',\n",
       " 'Poles',\n",
       " 'Panama',\n",
       " 'developed',\n",
       " 'unfortunately',\n",
       " 'survivors',\n",
       " 'September',\n",
       " 'Canada',\n",
       " 'Nambiar',\n",
       " 'discuss',\n",
       " 'airstrikes',\n",
       " 'record',\n",
       " 'air',\n",
       " 'space',\n",
       " 'clear',\n",
       " 'Aviv',\n",
       " 'avian',\n",
       " 'proceedings',\n",
       " 'involved',\n",
       " 'Commission',\n",
       " 'conservation',\n",
       " 'international',\n",
       " 'nine',\n",
       " 'All',\n",
       " 'matter',\n",
       " 'Conservative',\n",
       " '2001',\n",
       " 'Kandahar',\n",
       " 'found',\n",
       " 'enemy',\n",
       " 'allowed',\n",
       " 'down',\n",
       " 'academy',\n",
       " 'sacrificial',\n",
       " 'Clinton',\n",
       " 'Tal',\n",
       " 'operation',\n",
       " 'Kirkuk',\n",
       " 'Wild',\n",
       " 'urge',\n",
       " 'workforces',\n",
       " 'finally',\n",
       " 'use',\n",
       " 'drugmaker',\n",
       " 'suicide',\n",
       " '1973',\n",
       " 'sources',\n",
       " 'Aides',\n",
       " 'institute',\n",
       " 'Nairobi',\n",
       " 'fine',\n",
       " 'extremely',\n",
       " 'attack',\n",
       " 'extradition',\n",
       " 'Fund',\n",
       " 'Khabarovsk',\n",
       " 'neighborhood',\n",
       " 'reopen',\n",
       " 'houses',\n",
       " 'runoff',\n",
       " 'collecting',\n",
       " 'Osama',\n",
       " 'clashes',\n",
       " 'replace',\n",
       " 'Madden',\n",
       " 'towns',\n",
       " 'raping',\n",
       " 'Saturday',\n",
       " 'immigration',\n",
       " 'aircraft',\n",
       " 'senator',\n",
       " 'hour',\n",
       " 'Emirates',\n",
       " 'kidnappings',\n",
       " 'Islam',\n",
       " 'Northern',\n",
       " 'suspected',\n",
       " 'organizer',\n",
       " 'protects',\n",
       " 'scope',\n",
       " '50',\n",
       " 'support',\n",
       " 'study',\n",
       " 'raid',\n",
       " 'pregnant',\n",
       " 'Coalition',\n",
       " 'Reporters',\n",
       " 'Mercosur',\n",
       " 'Refugees',\n",
       " 'donate',\n",
       " 'current',\n",
       " 'request',\n",
       " 'Santa',\n",
       " 'medieval',\n",
       " 'Euphrates',\n",
       " 'us',\n",
       " 'Benin',\n",
       " 'contradict',\n",
       " 'higher',\n",
       " 'adopted',\n",
       " 'El',\n",
       " 'Costello',\n",
       " 'Gaza',\n",
       " 'enhance',\n",
       " 'personal',\n",
       " 'marines',\n",
       " 'deposit',\n",
       " 'Juan',\n",
       " 'Somalians',\n",
       " 'Instead',\n",
       " '12th',\n",
       " 'spoke',\n",
       " 'withdrawal',\n",
       " 'erupted',\n",
       " 'formally',\n",
       " 'exposure',\n",
       " 'jeopardize',\n",
       " 're-started',\n",
       " 'began',\n",
       " 'company',\n",
       " 'Bosco',\n",
       " 'Augusto',\n",
       " 'Obesity',\n",
       " '34',\n",
       " 'interview',\n",
       " 'Afghanistan',\n",
       " 'audit',\n",
       " 'procedures',\n",
       " 'involving',\n",
       " 'day',\n",
       " 'asylum-seeking',\n",
       " '30-day',\n",
       " 'Minister',\n",
       " 'arms',\n",
       " 'growth',\n",
       " 'royalties',\n",
       " 'Office',\n",
       " 'centers',\n",
       " 'Group',\n",
       " 'on',\n",
       " 'education',\n",
       " 'Korea',\n",
       " 'Palestinians',\n",
       " '1974',\n",
       " 'Daley',\n",
       " '95',\n",
       " 'stopped',\n",
       " 'harmful',\n",
       " 'Tom',\n",
       " 'Stoltenberg',\n",
       " 'dollars',\n",
       " 'properly',\n",
       " 'blasts',\n",
       " 'Guardian',\n",
       " 'consider',\n",
       " 'inevitable',\n",
       " 'traded',\n",
       " 'small',\n",
       " 'warheads',\n",
       " 'regulations',\n",
       " 'see',\n",
       " 'winds',\n",
       " 'MS-13',\n",
       " 'playing',\n",
       " 'men',\n",
       " 'named',\n",
       " 'why',\n",
       " 'woman',\n",
       " 'Sivaram',\n",
       " 'Polish',\n",
       " 'area',\n",
       " 'medium',\n",
       " 'extraordinary',\n",
       " 'Chakul',\n",
       " 'weekly',\n",
       " 'way',\n",
       " 'material',\n",
       " 'low-level',\n",
       " 'Development',\n",
       " 'Galina',\n",
       " 'flags',\n",
       " 'Hussein',\n",
       " 'originates',\n",
       " 'buying',\n",
       " 'Ohio-based',\n",
       " 'aide',\n",
       " 'positive',\n",
       " 'sending',\n",
       " 'Controversy',\n",
       " 'injury',\n",
       " 'guerrillas',\n",
       " 'access',\n",
       " 'gagged',\n",
       " 'Junichiro',\n",
       " 'startup',\n",
       " 'Hispanics',\n",
       " ',',\n",
       " 'potentially',\n",
       " 'extra',\n",
       " 'to',\n",
       " 'eight',\n",
       " 'Sutham',\n",
       " 'dialogue',\n",
       " 'Vision',\n",
       " 'lives',\n",
       " 'kidnapped',\n",
       " 'Vioxx',\n",
       " 'impunity',\n",
       " 'al-Rubaei',\n",
       " 'bribes',\n",
       " 'outbursts',\n",
       " 'board',\n",
       " 'Niger',\n",
       " 'workers',\n",
       " 'back',\n",
       " 'planet',\n",
       " 'criminal',\n",
       " 'relay',\n",
       " 'bordering',\n",
       " 'administering',\n",
       " 'Jianchao',\n",
       " 'less',\n",
       " 'obtained',\n",
       " 'Goatherd',\n",
       " 'Victor',\n",
       " 'Azahari',\n",
       " 'pressure',\n",
       " 'detainees',\n",
       " 'Andreu',\n",
       " 'television',\n",
       " 'centered',\n",
       " 'high-level',\n",
       " 'USSR',\n",
       " 'David',\n",
       " 'private',\n",
       " 'Fire',\n",
       " 'orchestrating',\n",
       " 'caused',\n",
       " 'Speaking',\n",
       " 'Aziz',\n",
       " 'airliner',\n",
       " 'quotes',\n",
       " 'summit',\n",
       " 'rebels',\n",
       " 'shop',\n",
       " 'ABC',\n",
       " 'hoped',\n",
       " 'latest',\n",
       " 'gunshot',\n",
       " 'farther',\n",
       " 'count',\n",
       " 'Rawalpindi',\n",
       " 'Colorado',\n",
       " 'Mahdi',\n",
       " 'Posada',\n",
       " 'Sint',\n",
       " 'majority',\n",
       " 'First',\n",
       " 'widely',\n",
       " 'jointly',\n",
       " 'Kampala',\n",
       " '2004',\n",
       " 'compound',\n",
       " 'electricity',\n",
       " 'witnessed',\n",
       " 'Later',\n",
       " 'briefly',\n",
       " 'side',\n",
       " 'heads',\n",
       " 'criminals',\n",
       " 'downstream',\n",
       " 'Hamas',\n",
       " 'state-approved',\n",
       " 'patrols',\n",
       " 'magnitude',\n",
       " 'gives',\n",
       " 'lawmakers',\n",
       " 'saw',\n",
       " 'sea',\n",
       " 'readings',\n",
       " '1994',\n",
       " 'fired',\n",
       " 'Rising',\n",
       " 'consular',\n",
       " 'Binh',\n",
       " 'terms',\n",
       " 'do',\n",
       " 'rise',\n",
       " 'Open',\n",
       " 'validated',\n",
       " 'provided',\n",
       " 'Prime',\n",
       " 'sought',\n",
       " 'Jersey',\n",
       " 'fighting',\n",
       " 'ceasefire',\n",
       " 'coast',\n",
       " 'enrichment',\n",
       " 'ends',\n",
       " 'hostage-takers',\n",
       " '13th',\n",
       " 'lady',\n",
       " 'jobs',\n",
       " 'elsewhere',\n",
       " 'clandestine',\n",
       " 'also',\n",
       " 'Millions',\n",
       " 'waste',\n",
       " 'sixth',\n",
       " '120',\n",
       " 'allegations',\n",
       " 'Israeli',\n",
       " 'blanketed',\n",
       " 'Bambang',\n",
       " 'lakeside',\n",
       " 'angered',\n",
       " 'Valley',\n",
       " ...}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(itertools.chain(*[[w for w in s] for s in train_sentences_words])) \n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'O'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = set(itertools.chain(*[[w for w in s] for s in train_sentences_tags]))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_lens = map(len, train_sentences_words)\n",
    "sentences_lens = list(sentences_lens)\n",
    "len(sentences_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4728, 17)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab), len(tags), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sentences_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 45., 193., 258., 284., 151.,  65.,  25.,   2.,   0.,   1.]),\n",
       " array([ 4. ,  9.8, 15.6, 21.4, 27.2, 33. , 38.8, 44.6, 50.4, 56.2, 62. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sentences_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_LEN = 75 \n",
    "MAX_LEN = max(sentences_lens)\n",
    "VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x1d1692fc320>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters=[], oov_token='__UNKNOWN__')\n",
    "words_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tokenizer.fit_on_texts(map(lambda s: ' '.join(s), train_sentences_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = words_tokenizer.word_index\n",
    "word_index['__PADDING__'] = 0\n",
    "word_index['special']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(k,v) for k,v in word_index.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens: 4435\n"
     ]
    }
   ],
   "source": [
    "index_word = {i:w for w, i in word_index.items()}\n",
    "print('Unique tokens:', len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 256\n"
     ]
    }
   ],
   "source": [
    "train_sequences = words_tokenizer.texts_to_sequences(map(lambda s: ' '.join(s), train_sentences_words))\n",
    "test_sequences = words_tokenizer.texts_to_sequences(map(lambda s: ' '.join(s), test_sentences_words))\n",
    "print(len(train_sequences), len(test_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 62) (256, 62)\n"
     ]
    }
   ],
   "source": [
    "train_sequences_padded = pad_sequences(train_sequences, maxlen=MAX_LEN)\n",
    "test_sequences_padded = pad_sequences(test_sequences, maxlen=MAX_LEN)\n",
    "print(train_sequences_padded.shape, test_sequences_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x1d1693e8668>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_tokenizer = Tokenizer(num_words=len(tags), filters='', oov_token='__UNKNOWN__', lower=False)\n",
    "tags_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_tokenizer.fit_on_texts(map(lambda s: ' '.join(s), train_sentences_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__UNKNOWN__': 1,\n",
       " 'O': 2,\n",
       " 'B-geo': 3,\n",
       " 'B-gpe': 4,\n",
       " 'B-org': 5,\n",
       " 'I-per': 6,\n",
       " 'B-tim': 7,\n",
       " 'B-per': 8,\n",
       " 'I-org': 9,\n",
       " 'I-geo': 10,\n",
       " 'I-tim': 11,\n",
       " 'B-art': 12,\n",
       " 'I-gpe': 13,\n",
       " 'I-art': 14,\n",
       " 'B-eve': 15,\n",
       " 'I-eve': 16,\n",
       " 'B-nat': 17,\n",
       " 'I-nat': 18,\n",
       " '__PADDING__': 0}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_index = tags_tokenizer.word_index\n",
    "tag_index['__PADDING__'] = 0\n",
    "tag_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tags: 19\n"
     ]
    }
   ],
   "source": [
    "index_tag = {i:w for w, i in tag_index.items()}\n",
    "\n",
    "index_tag_wo_padding = dict(index_tag)\n",
    "index_tag_wo_padding[tag_index['__PADDING__']] = '0'\n",
    "print('Unique tags:', len(tag_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 256)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags = tags_tokenizer.texts_to_sequences(map(lambda s: ' '.join(s), train_sentences_tags))\n",
    "test_tags = tags_tokenizer.texts_to_sequences(map(lambda s: ' '.join(s), test_sentences_tags))\n",
    "len(train_tags), len(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 62, 1) (256, 62, 1)\n"
     ]
    }
   ],
   "source": [
    "train_tags_padded = pad_sequences(train_tags, maxlen=MAX_LEN)\n",
    "test_tags_padded = pad_sequences(test_tags, maxlen=MAX_LEN)\n",
    "\n",
    "train_tags_padded = np.expand_dims(train_tags_padded, -1)\n",
    "test_tags_padded = np.expand_dims(test_tags_padded, -1)\n",
    "print(train_tags_padded.shape, test_tags_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_tags_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "not O\n",
      "counting O\n",
      "the O\n",
      "latest O\n",
      "death O\n",
      ", O\n",
      "the O\n",
      "world B-org\n",
      "health I-org\n",
      "organization I-org\n",
      "says O\n",
      "227 O\n",
      "people O\n",
      "around O\n",
      "the O\n",
      "world O\n",
      "have O\n",
      "died O\n",
      "from O\n",
      "bird O\n",
      "flu O\n",
      "since O\n",
      "2003 B-tim\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "for w, t in zip(train_sequences_padded[123], train_tags_padded[123]):\n",
    "    print(index_word[w], index_tag[t[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Bidirectional, Dropout\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4728"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VOCAB_SIZE = len(vocab)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 62)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 62, 300)           1418400   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 62, 128)           186880    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 62, 32)            4128      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 62, 19)            627       \n",
      "=================================================================\n",
      "Total params: 1,610,035\n",
      "Trainable params: 1,610,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random_embedding_layer = Embedding(VOCAB_SIZE,\n",
    "                                300,\n",
    "                                input_length=MAX_LEN)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_LEN,), dtype='int32')\n",
    "embedded_sequences = random_embedding_layer(sequence_input)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(embedded_sequences)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "preds = Dense(len(tag_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              #metrics=['sparse_categorical_accuracy'])\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 62), (256, 62))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_padded.shape, test_sequences_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 62, 1), (256, 62, 1))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags_padded.shape, test_tags_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(train_sequences_padded, train_tags_padded):\n",
    "    if len(x) != len(y):\n",
    "        print(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(test_sequences_padded, test_tags_padded):\n",
    "    if len(x) != len(y):\n",
    "        print(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1024 samples, validate on 256 samples\n",
      "Epoch 1/10\n",
      "1024/1024 [==============================] - ETA: 1:38 - loss: 2.9383 - categorical_accuracy: 0.00 - ETA: 49s - loss: 2.9139 - categorical_accuracy: 0.3007 - ETA: 33s - loss: 2.8906 - categorical_accuracy: 0.443 - ETA: 24s - loss: 2.8677 - categorical_accuracy: 0.519 - ETA: 19s - loss: 2.8399 - categorical_accuracy: 0.580 - ETA: 16s - loss: 2.8145 - categorical_accuracy: 0.609 - ETA: 14s - loss: 2.7814 - categorical_accuracy: 0.639 - ETA: 12s - loss: 2.7458 - categorical_accuracy: 0.661 - ETA: 10s - loss: 2.7062 - categorical_accuracy: 0.679 - ETA: 9s - loss: 2.6623 - categorical_accuracy: 0.696 - ETA: 8s - loss: 2.6142 - categorical_accuracy: 0.71 - ETA: 7s - loss: 2.5519 - categorical_accuracy: 0.72 - ETA: 6s - loss: 2.4817 - categorical_accuracy: 0.74 - ETA: 6s - loss: 2.4058 - categorical_accuracy: 0.76 - ETA: 5s - loss: 2.3392 - categorical_accuracy: 0.77 - ETA: 5s - loss: 2.2753 - categorical_accuracy: 0.79 - ETA: 4s - loss: 2.2050 - categorical_accuracy: 0.80 - ETA: 4s - loss: 2.1417 - categorical_accuracy: 0.81 - ETA: 3s - loss: 2.0865 - categorical_accuracy: 0.82 - ETA: 3s - loss: 2.0274 - categorical_accuracy: 0.82 - ETA: 2s - loss: 1.9697 - categorical_accuracy: 0.82 - ETA: 2s - loss: 1.9130 - categorical_accuracy: 0.82 - ETA: 2s - loss: 1.8586 - categorical_accuracy: 0.82 - ETA: 1s - loss: 1.8073 - categorical_accuracy: 0.81 - ETA: 1s - loss: 1.7566 - categorical_accuracy: 0.81 - ETA: 1s - loss: 1.7109 - categorical_accuracy: 0.80 - ETA: 1s - loss: 1.6665 - categorical_accuracy: 0.79 - ETA: 0s - loss: 1.6230 - categorical_accuracy: 0.79 - ETA: 0s - loss: 1.5834 - categorical_accuracy: 0.78 - ETA: 0s - loss: 1.5457 - categorical_accuracy: 0.78 - ETA: 0s - loss: 1.5089 - categorical_accuracy: 0.77 - 7s 7ms/step - loss: 1.4741 - categorical_accuracy: 0.7740 - val_loss: 0.3894 - val_categorical_accuracy: 0.6074\n",
      "Epoch 2/10\n",
      "1024/1024 [==============================] - ETA: 3s - loss: 0.4220 - categorical_accuracy: 0.60 - ETA: 3s - loss: 0.4009 - categorical_accuracy: 0.62 - ETA: 3s - loss: 0.3842 - categorical_accuracy: 0.61 - ETA: 3s - loss: 0.3766 - categorical_accuracy: 0.61 - ETA: 3s - loss: 0.3980 - categorical_accuracy: 0.61 - ETA: 3s - loss: 0.3852 - categorical_accuracy: 0.62 - ETA: 2s - loss: 0.3692 - categorical_accuracy: 0.62 - ETA: 2s - loss: 0.3674 - categorical_accuracy: 0.62 - ETA: 2s - loss: 0.3678 - categorical_accuracy: 0.62 - ETA: 2s - loss: 0.3623 - categorical_accuracy: 0.62 - ETA: 2s - loss: 0.3605 - categorical_accuracy: 0.62 - ETA: 2s - loss: 0.3568 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.3557 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.3504 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.3478 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.3467 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.3432 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.3428 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.3388 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.3328 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.3328 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.3317 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.3292 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.3298 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.3291 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.3256 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.3277 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.3263 - categorical_accuracy: 0.63 - ETA: 0s - loss: 0.3251 - categorical_accuracy: 0.63 - ETA: 0s - loss: 0.3256 - categorical_accuracy: 0.63 - ETA: 0s - loss: 0.3247 - categorical_accuracy: 0.63 - 4s 4ms/step - loss: 0.3222 - categorical_accuracy: 0.6400 - val_loss: 0.2848 - val_categorical_accuracy: 0.6310\n",
      "Epoch 3/10\n",
      "1024/1024 [==============================] - ETA: 3s - loss: 0.2756 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.2997 - categorical_accuracy: 0.64 - ETA: 3s - loss: 0.2835 - categorical_accuracy: 0.65 - ETA: 3s - loss: 0.2808 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.2675 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.2730 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.2766 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2738 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2727 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2721 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2740 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2705 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2716 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2734 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2722 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2725 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2713 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2687 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2693 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2682 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2695 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2704 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2701 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2696 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2697 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2689 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2659 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2658 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2666 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2665 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2667 - categorical_accuracy: 0.64 - 4s 4ms/step - loss: 0.2665 - categorical_accuracy: 0.6442 - val_loss: 0.2555 - val_categorical_accuracy: 0.6314\n",
      "Epoch 4/10\n",
      "1024/1024 [==============================] - ETA: 4s - loss: 0.2312 - categorical_accuracy: 0.65 - ETA: 4s - loss: 0.2384 - categorical_accuracy: 0.65 - ETA: 3s - loss: 0.2349 - categorical_accuracy: 0.64 - ETA: 3s - loss: 0.2457 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.2439 - categorical_accuracy: 0.64 - ETA: 3s - loss: 0.2502 - categorical_accuracy: 0.64 - ETA: 3s - loss: 0.2504 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2546 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.2529 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.2562 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.2517 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.2477 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2459 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2460 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2456 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2461 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2419 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2449 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2420 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2403 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2374 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2391 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.2372 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2364 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2365 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2366 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2341 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2339 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2337 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2337 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2336 - categorical_accuracy: 0.64 - 4s 4ms/step - loss: 0.2318 - categorical_accuracy: 0.6452 - val_loss: 0.2225 - val_categorical_accuracy: 0.6327\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - ETA: 3s - loss: 0.1922 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1870 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1994 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.2044 - categorical_accuracy: 0.62 - ETA: 2s - loss: 0.1993 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1952 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1920 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1889 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1888 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1894 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1922 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1908 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1910 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.1900 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.1917 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1938 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.1949 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1961 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1962 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1966 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1952 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1942 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1937 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1921 - categorical_accuracy: 0.65 - ETA: 0s - loss: 0.1932 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1932 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1915 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1899 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1891 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1878 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1884 - categorical_accuracy: 0.64 - 4s 4ms/step - loss: 0.1883 - categorical_accuracy: 0.6475 - val_loss: 0.1925 - val_categorical_accuracy: 0.6340\n",
      "Epoch 6/10\n",
      "1024/1024 [==============================] - ETA: 3s - loss: 0.1719 - categorical_accuracy: 0.66 - ETA: 3s - loss: 0.1783 - categorical_accuracy: 0.66 - ETA: 3s - loss: 0.1830 - categorical_accuracy: 0.65 - ETA: 3s - loss: 0.1802 - categorical_accuracy: 0.65 - ETA: 3s - loss: 0.1663 - categorical_accuracy: 0.66 - ETA: 3s - loss: 0.1667 - categorical_accuracy: 0.66 - ETA: 3s - loss: 0.1654 - categorical_accuracy: 0.65 - ETA: 3s - loss: 0.1598 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1558 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1586 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1608 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1648 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1647 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1635 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1647 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1639 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1625 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1607 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1611 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1604 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1595 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1578 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1583 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1581 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1580 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1561 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1548 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1539 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1542 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1542 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1530 - categorical_accuracy: 0.64 - 4s 4ms/step - loss: 0.1538 - categorical_accuracy: 0.6477 - val_loss: 0.1784 - val_categorical_accuracy: 0.6338\n",
      "Epoch 7/10\n",
      "1024/1024 [==============================] - ETA: 3s - loss: 0.1240 - categorical_accuracy: 0.67 - ETA: 3s - loss: 0.1254 - categorical_accuracy: 0.64 - ETA: 3s - loss: 0.1293 - categorical_accuracy: 0.65 - ETA: 3s - loss: 0.1204 - categorical_accuracy: 0.65 - ETA: 3s - loss: 0.1322 - categorical_accuracy: 0.65 - ETA: 3s - loss: 0.1303 - categorical_accuracy: 0.65 - ETA: 3s - loss: 0.1336 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1337 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1328 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1291 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1303 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1304 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1283 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1285 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1283 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1291 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1326 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1331 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1329 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1332 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1347 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1364 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1354 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1340 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1335 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1341 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1331 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1321 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1328 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1333 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1327 - categorical_accuracy: 0.64 - 4s 4ms/step - loss: 0.1319 - categorical_accuracy: 0.6461 - val_loss: 0.1716 - val_categorical_accuracy: 0.6322\n",
      "Epoch 8/10\n",
      "1024/1024 [==============================] - ETA: 4s - loss: 0.1359 - categorical_accuracy: 0.64 - ETA: 4s - loss: 0.1248 - categorical_accuracy: 0.63 - ETA: 4s - loss: 0.1358 - categorical_accuracy: 0.63 - ETA: 4s - loss: 0.1243 - categorical_accuracy: 0.62 - ETA: 4s - loss: 0.1187 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1221 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1194 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1145 - categorical_accuracy: 0.64 - ETA: 3s - loss: 0.1150 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1164 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1134 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1124 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1116 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1097 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1107 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1099 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1117 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1113 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1097 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1091 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1112 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1109 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1109 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1122 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1126 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1127 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1128 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1131 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1134 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1139 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1146 - categorical_accuracy: 0.64 - 5s 4ms/step - loss: 0.1148 - categorical_accuracy: 0.6450 - val_loss: 0.1652 - val_categorical_accuracy: 0.6316\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - ETA: 4s - loss: 0.1116 - categorical_accuracy: 0.63 - ETA: 4s - loss: 0.1162 - categorical_accuracy: 0.63 - ETA: 4s - loss: 0.1101 - categorical_accuracy: 0.64 - ETA: 4s - loss: 0.1155 - categorical_accuracy: 0.63 - ETA: 4s - loss: 0.1142 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1080 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1062 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1057 - categorical_accuracy: 0.64 - ETA: 3s - loss: 0.1057 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.1032 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1036 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1046 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1054 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1057 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1038 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1020 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1016 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1013 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1007 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1014 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1004 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.0990 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.0982 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.0999 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1005 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1005 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1002 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1000 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1003 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0997 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0998 - categorical_accuracy: 0.64 - 4s 4ms/step - loss: 0.0996 - categorical_accuracy: 0.6444 - val_loss: 0.1629 - val_categorical_accuracy: 0.6314\n",
      "Epoch 10/10\n",
      "1024/1024 [==============================] - ETA: 4s - loss: 0.0936 - categorical_accuracy: 0.65 - ETA: 4s - loss: 0.0879 - categorical_accuracy: 0.61 - ETA: 4s - loss: 0.0814 - categorical_accuracy: 0.63 - ETA: 4s - loss: 0.0811 - categorical_accuracy: 0.64 - ETA: 4s - loss: 0.0769 - categorical_accuracy: 0.64 - ETA: 3s - loss: 0.0818 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.0813 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.0792 - categorical_accuracy: 0.64 - ETA: 3s - loss: 0.0825 - categorical_accuracy: 0.63 - ETA: 3s - loss: 0.0829 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0809 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0824 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0831 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0828 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0850 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0851 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0844 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0836 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.0840 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.0842 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.0834 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.0836 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.0835 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.0846 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0840 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0839 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0837 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0833 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0832 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0829 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0836 - categorical_accuracy: 0.64 - 5s 5ms/step - loss: 0.0833 - categorical_accuracy: 0.6440 - val_loss: 0.1639 - val_categorical_accuracy: 0.6312\n",
      "Wall time: 48.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d169274358>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(train_sequences_padded, train_tags_padded, batch_size=32, epochs=10, \\\n",
    "                validation_data=(test_sequences_padded, test_tags_padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 508 ms\n"
     ]
    }
   ],
   "source": [
    "%time lstm_predicted = model.predict(test_sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted_tags = []\n",
    "bow_predicted_tags = []\n",
    "for s, s_pred in zip(test_sentences_words, lstm_predicted):\n",
    "    tags = np.argmax(s_pred, axis=1)\n",
    "    tags = list(map(index_tag_wo_padding.get, tags))[-len(s):]\n",
    "    lstm_predicted_tags.append(tags)\n",
    "    \n",
    "    bow_vector, _ = sentences_to_instances([s], [['x']*len(s)], count_vectorizer)\n",
    "    bow_predicted = clf.predict(bow_vector)[0]\n",
    "    bow_predicted_tags.append(bow_predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted_tags = []\n",
    "bow_predicted_tags = []\n",
    "for s, s_pred in zip(test_sentences_words, lstm_predicted):\n",
    "    tags = np.argmax(s_pred, axis=1)\n",
    "    tags = list(map(index_tag_wo_padding.get,tags))[-len(s):]\n",
    "    lstm_predicted_tags.append(tags)\n",
    "    \n",
    "    bow_vector, _ = sentences_to_instances([s], [['x']*len(s)], count_vectorizer)\n",
    "    bow_predicted = clf.predict(bow_vector)[0]\n",
    "    bow_predicted_tags.append(bow_predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "===============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        tim       0.74      0.49      0.59       111\n",
      "        per       0.45      0.24      0.31        93\n",
      "        org       0.37      0.19      0.25       145\n",
      "        gpe       0.44      0.81      0.57        85\n",
      "        geo       0.48      0.38      0.43       186\n",
      "        nat       0.00      0.00      0.00         3\n",
      "        art       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.48      0.39      0.41       628\n",
      "\n",
      "\n",
      "BOW\n",
      "===============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        tim       0.00      0.00      0.00       111\n",
      "        per       0.00      0.00      0.00        93\n",
      "        org       0.00      0.00      0.00       145\n",
      "        gpe       0.00      0.00      0.00        85\n",
      "        geo       0.00      0.00      0.00       186\n",
      "        nat       0.00      0.00      0.00         3\n",
      "        art       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.00      0.00      0.00       628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LSTM')\n",
    "print('='*15)\n",
    "print(classification_report(test_sentences_tags, lstm_predicted_tags))\n",
    "print()\n",
    "print('BOW')\n",
    "print('='*15)\n",
    "print(classification_report(test_sentences_tags, bow_predicted_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM: 0.42995594713656393\n",
      "BOW: 0\n"
     ]
    }
   ],
   "source": [
    "print('LSTM:', f1_score(test_sentences_tags, lstm_predicted_tags))\n",
    "print('BOW:', f1_score(test_sentences_tags, bow_predicted_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Trained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Continuum\\\\anaconda3\\\\envs\\\\crtasks\\\\notebooks\\\\SequenceModels'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = os.getcwd() + '\\\\glove.6B\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# vectors: 399883\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'), encoding=\"ISO-8859-1\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        if len(values[1:]) == 300:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = coefs\n",
    "\n",
    "        #print('# values:',  len(values[1:]))\n",
    "\n",
    "print('# vectors:',  len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "num_words = min(VOCAB_SIZE, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, 300))\n",
    "for word, i in word_index.items():\n",
    "    if i >= VOCAB_SIZE:\n",
    "        continue\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 62)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 62, 300)           1418400   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 62, 128)           186880    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 62, 32)            4128      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 62, 19)            627       \n",
      "=================================================================\n",
      "Total params: 1,610,035\n",
      "Trainable params: 191,635\n",
      "Non-trainable params: 1,418,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_embedding_layer = Embedding(VOCAB_SIZE,\n",
    "                                300,\n",
    "                                embeddings_initializer=Constant(embedding_matrix),\n",
    "                                input_length=MAX_LEN,\n",
    "                                trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_LEN,), dtype='int32')\n",
    "embedded_sequences = pretrained_embedding_layer(sequence_input)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(embedded_sequences)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "preds = Dense(len(tag_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              #metrics=['sparse_categorical_accuracy'])\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1024 samples, validate on 256 samples\n",
      "Epoch 1/10\n",
      "1024/1024 [==============================] - ETA: 1:32 - loss: 2.8738 - categorical_accuracy: 0.0000e+ - ETA: 45s - loss: 2.8185 - categorical_accuracy: 0.0491     - ETA: 30s - loss: 2.7630 - categorical_accuracy: 0.091 - ETA: 22s - loss: 2.7189 - categorical_accuracy: 0.123 - ETA: 17s - loss: 2.6737 - categorical_accuracy: 0.146 - ETA: 14s - loss: 2.6244 - categorical_accuracy: 0.160 - ETA: 12s - loss: 2.5808 - categorical_accuracy: 0.169 - ETA: 10s - loss: 2.5353 - categorical_accuracy: 0.176 - ETA: 9s - loss: 2.4943 - categorical_accuracy: 0.182 - ETA: 8s - loss: 2.4466 - categorical_accuracy: 0.18 - ETA: 7s - loss: 2.4161 - categorical_accuracy: 0.18 - ETA: 6s - loss: 2.3836 - categorical_accuracy: 0.19 - ETA: 5s - loss: 2.3519 - categorical_accuracy: 0.19 - ETA: 5s - loss: 2.3284 - categorical_accuracy: 0.19 - ETA: 4s - loss: 2.2992 - categorical_accuracy: 0.19 - ETA: 4s - loss: 2.2756 - categorical_accuracy: 0.19 - ETA: 3s - loss: 2.2425 - categorical_accuracy: 0.19 - ETA: 3s - loss: 2.2082 - categorical_accuracy: 0.19 - ETA: 2s - loss: 2.1777 - categorical_accuracy: 0.19 - ETA: 2s - loss: 2.1426 - categorical_accuracy: 0.19 - ETA: 2s - loss: 2.1025 - categorical_accuracy: 0.19 - ETA: 2s - loss: 2.0627 - categorical_accuracy: 0.20 - ETA: 1s - loss: 2.0200 - categorical_accuracy: 0.21 - ETA: 1s - loss: 1.9797 - categorical_accuracy: 0.22 - ETA: 1s - loss: 1.9352 - categorical_accuracy: 0.24 - ETA: 1s - loss: 1.8903 - categorical_accuracy: 0.25 - ETA: 0s - loss: 1.8507 - categorical_accuracy: 0.27 - ETA: 0s - loss: 1.8072 - categorical_accuracy: 0.28 - ETA: 0s - loss: 1.7660 - categorical_accuracy: 0.29 - ETA: 0s - loss: 1.7265 - categorical_accuracy: 0.31 - ETA: 0s - loss: 1.6888 - categorical_accuracy: 0.32 - 6s 6ms/step - loss: 1.6525 - categorical_accuracy: 0.3353 - val_loss: 0.5383 - val_categorical_accuracy: 0.7051\n",
      "Epoch 2/10\n",
      "1024/1024 [==============================] - ETA: 2s - loss: 0.5236 - categorical_accuracy: 0.71 - ETA: 2s - loss: 0.5183 - categorical_accuracy: 0.70 - ETA: 2s - loss: 0.5099 - categorical_accuracy: 0.71 - ETA: 2s - loss: 0.5145 - categorical_accuracy: 0.70 - ETA: 2s - loss: 0.4851 - categorical_accuracy: 0.71 - ETA: 2s - loss: 0.4799 - categorical_accuracy: 0.71 - ETA: 2s - loss: 0.4730 - categorical_accuracy: 0.70 - ETA: 2s - loss: 0.4600 - categorical_accuracy: 0.70 - ETA: 1s - loss: 0.4516 - categorical_accuracy: 0.69 - ETA: 1s - loss: 0.4378 - categorical_accuracy: 0.69 - ETA: 1s - loss: 0.4301 - categorical_accuracy: 0.69 - ETA: 1s - loss: 0.4235 - categorical_accuracy: 0.68 - ETA: 1s - loss: 0.4192 - categorical_accuracy: 0.68 - ETA: 1s - loss: 0.4107 - categorical_accuracy: 0.68 - ETA: 1s - loss: 0.4069 - categorical_accuracy: 0.67 - ETA: 1s - loss: 0.4003 - categorical_accuracy: 0.67 - ETA: 1s - loss: 0.3965 - categorical_accuracy: 0.67 - ETA: 1s - loss: 0.3909 - categorical_accuracy: 0.67 - ETA: 1s - loss: 0.3838 - categorical_accuracy: 0.67 - ETA: 1s - loss: 0.3829 - categorical_accuracy: 0.67 - ETA: 0s - loss: 0.3743 - categorical_accuracy: 0.67 - ETA: 0s - loss: 0.3688 - categorical_accuracy: 0.67 - ETA: 0s - loss: 0.3632 - categorical_accuracy: 0.66 - ETA: 0s - loss: 0.3579 - categorical_accuracy: 0.66 - ETA: 0s - loss: 0.3543 - categorical_accuracy: 0.66 - ETA: 0s - loss: 0.3521 - categorical_accuracy: 0.66 - ETA: 0s - loss: 0.3473 - categorical_accuracy: 0.66 - ETA: 0s - loss: 0.3446 - categorical_accuracy: 0.66 - ETA: 0s - loss: 0.3408 - categorical_accuracy: 0.66 - ETA: 0s - loss: 0.3396 - categorical_accuracy: 0.66 - ETA: 0s - loss: 0.3354 - categorical_accuracy: 0.66 - 3s 3ms/step - loss: 0.3330 - categorical_accuracy: 0.6639 - val_loss: 0.2526 - val_categorical_accuracy: 0.6372\n",
      "Epoch 3/10\n",
      "1024/1024 [==============================] - ETA: 2s - loss: 0.2265 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.2368 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.2338 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.2358 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.2333 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.2294 - categorical_accuracy: 0.66 - ETA: 2s - loss: 0.2238 - categorical_accuracy: 0.66 - ETA: 1s - loss: 0.2307 - categorical_accuracy: 0.66 - ETA: 1s - loss: 0.2307 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.2320 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.2357 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.2320 - categorical_accuracy: 0.66 - ETA: 1s - loss: 0.2304 - categorical_accuracy: 0.66 - ETA: 1s - loss: 0.2299 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.2300 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.2291 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.2272 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.2255 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.2271 - categorical_accuracy: 0.65 - ETA: 0s - loss: 0.2250 - categorical_accuracy: 0.65 - ETA: 0s - loss: 0.2248 - categorical_accuracy: 0.65 - ETA: 0s - loss: 0.2259 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2237 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2243 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2237 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2250 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2231 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2228 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2218 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2203 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.2187 - categorical_accuracy: 0.64 - 3s 3ms/step - loss: 0.2180 - categorical_accuracy: 0.6481 - val_loss: 0.2138 - val_categorical_accuracy: 0.6353\n",
      "Epoch 4/10\n",
      "1024/1024 [==============================] - ETA: 2s - loss: 0.1934 - categorical_accuracy: 0.60 - ETA: 2s - loss: 0.2138 - categorical_accuracy: 0.60 - ETA: 1s - loss: 0.2034 - categorical_accuracy: 0.61 - ETA: 1s - loss: 0.1945 - categorical_accuracy: 0.62 - ETA: 1s - loss: 0.1941 - categorical_accuracy: 0.62 - ETA: 1s - loss: 0.1988 - categorical_accuracy: 0.62 - ETA: 1s - loss: 0.1996 - categorical_accuracy: 0.62 - ETA: 1s - loss: 0.2043 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.2032 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1993 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1965 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1945 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1929 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1956 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1950 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1946 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1927 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1918 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1903 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1901 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1885 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1868 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1857 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1833 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1819 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1828 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1827 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1817 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1820 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1822 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1817 - categorical_accuracy: 0.64 - 3s 3ms/step - loss: 0.1815 - categorical_accuracy: 0.6468 - val_loss: 0.1841 - val_categorical_accuracy: 0.6350\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - ETA: 2s - loss: 0.2124 - categorical_accuracy: 0.66 - ETA: 2s - loss: 0.1821 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1743 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1674 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1723 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1695 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.1631 - categorical_accuracy: 0.65 - ETA: 1s - loss: 0.1667 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1688 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1686 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1678 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1666 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1650 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1626 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1615 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1589 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1588 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1563 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1550 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1553 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1577 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1563 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1577 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1555 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1556 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1550 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1535 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1553 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1574 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1550 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1552 - categorical_accuracy: 0.64 - 3s 3ms/step - loss: 0.1542 - categorical_accuracy: 0.6462 - val_loss: 0.1627 - val_categorical_accuracy: 0.6342\n",
      "Epoch 6/10\n",
      "1024/1024 [==============================] - ETA: 2s - loss: 0.1491 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1343 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1411 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1588 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1557 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1530 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1486 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1477 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1478 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1494 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1491 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1463 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1472 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1444 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1438 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1432 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1409 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1403 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1419 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1415 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1433 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1419 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1405 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1387 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1378 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1377 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1374 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1358 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1349 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1357 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1353 - categorical_accuracy: 0.64 - 3s 3ms/step - loss: 0.1337 - categorical_accuracy: 0.6456 - val_loss: 0.1492 - val_categorical_accuracy: 0.6339\n",
      "Epoch 7/10\n",
      "1024/1024 [==============================] - ETA: 2s - loss: 0.1262 - categorical_accuracy: 0.66 - ETA: 2s - loss: 0.1141 - categorical_accuracy: 0.66 - ETA: 2s - loss: 0.1225 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1233 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1287 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1265 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1233 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1204 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1197 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1199 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1203 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1208 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1212 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1196 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1189 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1197 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1193 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1185 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1166 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1162 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1159 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1170 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1169 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1170 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1158 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1169 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1162 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1168 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1173 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1184 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1185 - categorical_accuracy: 0.64 - 3s 3ms/step - loss: 0.1199 - categorical_accuracy: 0.6451 - val_loss: 0.1414 - val_categorical_accuracy: 0.6339\n",
      "Epoch 8/10\n",
      "1024/1024 [==============================] - ETA: 2s - loss: 0.1262 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1183 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1106 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1068 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1081 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1101 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1120 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1129 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1147 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1165 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1128 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1097 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1111 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1116 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1105 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1093 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1099 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1110 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1110 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1103 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1110 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1110 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1111 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1105 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1104 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1115 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1115 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1107 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1103 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1098 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1087 - categorical_accuracy: 0.64 - 3s 3ms/step - loss: 0.1089 - categorical_accuracy: 0.6449 - val_loss: 0.1359 - val_categorical_accuracy: 0.6338\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - ETA: 2s - loss: 0.1109 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1115 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1236 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1161 - categorical_accuracy: 0.63 - ETA: 2s - loss: 0.1211 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1138 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1140 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.1113 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1104 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1090 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1060 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1079 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1086 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1081 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1081 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1076 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1070 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1035 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1048 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1035 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1032 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1021 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1012 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1000 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1010 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1005 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1000 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1012 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1017 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1014 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.1011 - categorical_accuracy: 0.64 - 3s 3ms/step - loss: 0.1013 - categorical_accuracy: 0.6451 - val_loss: 0.1306 - val_categorical_accuracy: 0.6338\n",
      "Epoch 10/10\n",
      "1024/1024 [==============================] - ETA: 2s - loss: 0.0991 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0906 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.0957 - categorical_accuracy: 0.65 - ETA: 2s - loss: 0.1006 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0993 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0963 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0956 - categorical_accuracy: 0.64 - ETA: 2s - loss: 0.0974 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1029 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1060 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1045 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1016 - categorical_accuracy: 0.64 - ETA: 1s - loss: 0.1014 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.1003 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.0981 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.0980 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.0974 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.0978 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.0965 - categorical_accuracy: 0.63 - ETA: 1s - loss: 0.0958 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0957 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0948 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0939 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0933 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0934 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0928 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0933 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0926 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0942 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0935 - categorical_accuracy: 0.64 - ETA: 0s - loss: 0.0936 - categorical_accuracy: 0.64 - 3s 3ms/step - loss: 0.0936 - categorical_accuracy: 0.6446 - val_loss: 0.1275 - val_categorical_accuracy: 0.6337\n",
      "Wall time: 34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d169274320>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(train_sequences_padded, train_tags_padded, batch_size=32, epochs=10,\\\n",
    "                validation_data=(test_sequences_padded, test_tags_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = model.predict(test_sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted_tags = []\n",
    "for s, s_pred in zip(test_sentences_words, lstm_predicted):\n",
    "    tags = np.argmax(s_pred, axis=1)\n",
    "    tags = list(map(index_tag_wo_padding.get,tags))[-len(s):]\n",
    "    lstm_predicted_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM + Pretrained Embbeddings\n",
      "===============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        tim       0.66      0.53      0.59       111\n",
      "        per       0.46      0.34      0.40        93\n",
      "        org       0.35      0.19      0.24       145\n",
      "        gpe       0.51      0.88      0.65        85\n",
      "        geo       0.66      0.46      0.54       186\n",
      "        nat       0.00      0.00      0.00         3\n",
      "        art       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.53      0.44      0.47       628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LSTM + Pretrained Embbeddings')\n",
    "print('='*15)\n",
    "print(classification_report(test_sentences_tags, lstm_predicted_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM+Glove: 0.4744027303754266\n"
     ]
    }
   ],
   "source": [
    "print('LSTM+Glove:', f1_score(test_sentences_tags, lstm_predicted_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/aggregation/scaling:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with aggregation/scaling\n",
      "INFO:tensorflow:Initialize variable module_1/aggregation/weights:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with aggregation/weights\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_0:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/W_cnn_0\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_1:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/W_cnn_1\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_2:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/W_cnn_2\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_3:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/W_cnn_3\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_4:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/W_cnn_4\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_5:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/W_cnn_5\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_6:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/W_cnn_6\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_0:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/b_cnn_0\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_1:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/b_cnn_1\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_2:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/b_cnn_2\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_3:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/b_cnn_3\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_4:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/b_cnn_4\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_5:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/b_cnn_5\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_6:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN/b_cnn_6\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/W_carry:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_high_0/W_carry\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/W_transform:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_high_0/W_transform\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/b_carry:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_high_0/b_carry\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/b_transform:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_high_0/b_transform\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/W_carry:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_high_1/W_carry\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/W_transform:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_high_1/W_transform\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/b_carry:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_high_1/b_carry\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/b_transform:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_high_1/b_transform\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_proj/W_proj:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_proj/W_proj\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/CNN_proj/b_proj:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/CNN_proj/b_proj\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable module_1/bilm/char_embed:0 from checkpoint b'C:\\\\Users\\\\Praveen.TN\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d\\\\variables\\\\variables' with bilm/char_embed\n"
     ]
    }
   ],
   "source": [
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(inputs={\n",
    "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
    "                            \"sequence_len\": tf.constant(32*[MAX_LEN])\n",
    "                      },\n",
    "                      signature=\"tokens\",\n",
    "                      as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 62)                0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 62, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 62, 128)           557568    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 62, 32)            4128      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 62, 19)            627       \n",
      "=================================================================\n",
      "Total params: 562,323\n",
      "Trainable params: 562,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "elmo_embedding_layer = Lambda(ElmoEmbedding, output_shape=(MAX_LEN, 1024))\n",
    "\n",
    "#sequence_input = Input(shape=(MAX_LEN,), dtype=tf.string)\n",
    "sequence_input = Input(shape=(MAX_LEN,), dtype=tf.string)\n",
    "\n",
    "embedded_sequences = elmo_embedding_layer(sequence_input)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(embedded_sequences)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "preds = Dense(len(tag_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_words_padded = [[index_word[w] for w in s] for s in train_sequences_padded]\n",
    "new_test_words_padded = [[index_word[w] for w in s] for s in test_sequences_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 62), (1024, 62, 1), (256, 62), (256, 62, 1))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_words_padded = np.array(new_train_words_padded[:32*32])\n",
    "new_train_tags_padded = train_tags_padded[:32*32]\n",
    "\n",
    "new_test_words_padded = np.array(new_test_words_padded[:8*32])\n",
    "new_test_tags_padded = test_tags_padded[:8*32]\n",
    "\n",
    "\n",
    "new_train_words_padded.shape, new_train_tags_padded.shape, new_test_words_padded.shape, new_test_tags_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1024 samples, validate on 256 samples\n",
      "Epoch 1/4\n",
      "1024/1024 [==============================] - ETA: 7:30 - loss: 3.1271 - categorical_accuracy: 0.00 - ETA: 6:32 - loss: 2.6629 - categorical_accuracy: 0.33 - ETA: 6:10 - loss: 2.3536 - categorical_accuracy: 0.46 - ETA: 5:55 - loss: 2.1054 - categorical_accuracy: 0.53 - ETA: 5:40 - loss: 1.9264 - categorical_accuracy: 0.58 - ETA: 5:25 - loss: 1.7854 - categorical_accuracy: 0.59 - ETA: 5:11 - loss: 1.6585 - categorical_accuracy: 0.61 - ETA: 5:01 - loss: 1.5413 - categorical_accuracy: 0.62 - ETA: 4:50 - loss: 1.4496 - categorical_accuracy: 0.63 - ETA: 4:42 - loss: 1.3649 - categorical_accuracy: 0.63 - ETA: 4:32 - loss: 1.2884 - categorical_accuracy: 0.63 - ETA: 4:22 - loss: 1.2168 - categorical_accuracy: 0.63 - ETA: 4:09 - loss: 1.1592 - categorical_accuracy: 0.63 - ETA: 3:55 - loss: 1.1034 - categorical_accuracy: 0.64 - ETA: 3:42 - loss: 1.0506 - categorical_accuracy: 0.64 - ETA: 3:29 - loss: 1.0083 - categorical_accuracy: 0.64 - ETA: 3:17 - loss: 0.9684 - categorical_accuracy: 0.64 - ETA: 3:05 - loss: 0.9364 - categorical_accuracy: 0.64 - ETA: 2:51 - loss: 0.9074 - categorical_accuracy: 0.64 - ETA: 2:41 - loss: 0.8771 - categorical_accuracy: 0.64 - ETA: 2:28 - loss: 0.8533 - categorical_accuracy: 0.64 - ETA: 2:14 - loss: 0.8287 - categorical_accuracy: 0.64 - ETA: 2:01 - loss: 0.8061 - categorical_accuracy: 0.64 - ETA: 1:47 - loss: 0.7872 - categorical_accuracy: 0.64 - ETA: 1:34 - loss: 0.7681 - categorical_accuracy: 0.64 - ETA: 1:21 - loss: 0.7509 - categorical_accuracy: 0.64 - ETA: 1:07 - loss: 0.7353 - categorical_accuracy: 0.64 - ETA: 54s - loss: 0.7166 - categorical_accuracy: 0.6429 - ETA: 40s - loss: 0.7024 - categorical_accuracy: 0.642 - ETA: 26s - loss: 0.6870 - categorical_accuracy: 0.642 - ETA: 13s - loss: 0.6727 - categorical_accuracy: 0.644 - 535s 522ms/step - loss: 0.6616 - categorical_accuracy: 0.6429 - val_loss: 0.3468 - val_categorical_accuracy: 0.6690\n",
      "Epoch 2/4\n",
      "1024/1024 [==============================] - ETA: 6:55 - loss: 0.1670 - categorical_accuracy: 0.66 - ETA: 7:11 - loss: 0.2242 - categorical_accuracy: 0.63 - ETA: 6:49 - loss: 0.2106 - categorical_accuracy: 0.64 - ETA: 6:24 - loss: 0.2177 - categorical_accuracy: 0.64 - ETA: 6:05 - loss: 0.2124 - categorical_accuracy: 0.64 - ETA: 5:53 - loss: 0.2197 - categorical_accuracy: 0.64 - ETA: 5:45 - loss: 0.2177 - categorical_accuracy: 0.64 - ETA: 5:31 - loss: 0.2181 - categorical_accuracy: 0.64 - ETA: 5:16 - loss: 0.2206 - categorical_accuracy: 0.64 - ETA: 5:01 - loss: 0.2222 - categorical_accuracy: 0.64 - ETA: 4:47 - loss: 0.2208 - categorical_accuracy: 0.64 - ETA: 4:32 - loss: 0.2235 - categorical_accuracy: 0.63 - ETA: 4:18 - loss: 0.2182 - categorical_accuracy: 0.63 - ETA: 4:03 - loss: 0.2157 - categorical_accuracy: 0.63 - ETA: 3:52 - loss: 0.2123 - categorical_accuracy: 0.64 - ETA: 3:38 - loss: 0.2102 - categorical_accuracy: 0.64 - ETA: 3:25 - loss: 0.2103 - categorical_accuracy: 0.64 - ETA: 3:10 - loss: 0.2112 - categorical_accuracy: 0.64 - ETA: 2:56 - loss: 0.2122 - categorical_accuracy: 0.64 - ETA: 2:42 - loss: 0.2112 - categorical_accuracy: 0.64 - ETA: 2:29 - loss: 0.2108 - categorical_accuracy: 0.64 - ETA: 2:15 - loss: 0.2088 - categorical_accuracy: 0.64 - ETA: 2:02 - loss: 0.2062 - categorical_accuracy: 0.64 - ETA: 1:48 - loss: 0.2045 - categorical_accuracy: 0.64 - ETA: 1:35 - loss: 0.2019 - categorical_accuracy: 0.64 - ETA: 1:21 - loss: 0.2002 - categorical_accuracy: 0.64 - ETA: 1:08 - loss: 0.2000 - categorical_accuracy: 0.64 - ETA: 54s - loss: 0.1996 - categorical_accuracy: 0.6446 - ETA: 40s - loss: 0.1978 - categorical_accuracy: 0.644 - ETA: 27s - loss: 0.1972 - categorical_accuracy: 0.645 - ETA: 13s - loss: 0.1968 - categorical_accuracy: 0.644 - 543s 530ms/step - loss: 0.1957 - categorical_accuracy: 0.6446 - val_loss: 0.2824 - val_categorical_accuracy: 0.6668\n",
      "Epoch 3/4\n",
      "1024/1024 [==============================] - ETA: 7:22 - loss: 0.1320 - categorical_accuracy: 0.66 - ETA: 7:20 - loss: 0.1453 - categorical_accuracy: 0.64 - ETA: 6:58 - loss: 0.1750 - categorical_accuracy: 0.63 - ETA: 6:36 - loss: 0.1766 - categorical_accuracy: 0.64 - ETA: 6:19 - loss: 0.1690 - categorical_accuracy: 0.64 - ETA: 6:05 - loss: 0.1707 - categorical_accuracy: 0.64 - ETA: 5:49 - loss: 0.1655 - categorical_accuracy: 0.64 - ETA: 5:33 - loss: 0.1632 - categorical_accuracy: 0.64 - ETA: 5:20 - loss: 0.1620 - categorical_accuracy: 0.64 - ETA: 5:05 - loss: 0.1598 - categorical_accuracy: 0.64 - ETA: 4:53 - loss: 0.1568 - categorical_accuracy: 0.64 - ETA: 4:41 - loss: 0.1529 - categorical_accuracy: 0.64 - ETA: 4:27 - loss: 0.1532 - categorical_accuracy: 0.64 - ETA: 4:13 - loss: 0.1523 - categorical_accuracy: 0.64 - ETA: 3:58 - loss: 0.1522 - categorical_accuracy: 0.64 - ETA: 3:44 - loss: 0.1512 - categorical_accuracy: 0.64 - ETA: 3:29 - loss: 0.1517 - categorical_accuracy: 0.64 - ETA: 3:15 - loss: 0.1513 - categorical_accuracy: 0.64 - ETA: 3:00 - loss: 0.1508 - categorical_accuracy: 0.64 - ETA: 2:46 - loss: 0.1517 - categorical_accuracy: 0.64 - ETA: 2:32 - loss: 0.1505 - categorical_accuracy: 0.64 - ETA: 2:18 - loss: 0.1495 - categorical_accuracy: 0.64 - ETA: 2:03 - loss: 0.1483 - categorical_accuracy: 0.64 - ETA: 1:50 - loss: 0.1469 - categorical_accuracy: 0.64 - ETA: 1:36 - loss: 0.1467 - categorical_accuracy: 0.64 - ETA: 1:22 - loss: 0.1462 - categorical_accuracy: 0.64 - ETA: 1:08 - loss: 0.1449 - categorical_accuracy: 0.64 - ETA: 54s - loss: 0.1447 - categorical_accuracy: 0.6447 - ETA: 41s - loss: 0.1434 - categorical_accuracy: 0.645 - ETA: 27s - loss: 0.1427 - categorical_accuracy: 0.645 - ETA: 13s - loss: 0.1414 - categorical_accuracy: 0.644 - 552s 539ms/step - loss: 0.1416 - categorical_accuracy: 0.6440 - val_loss: 0.2518 - val_categorical_accuracy: 0.6668\n",
      "Epoch 4/4\n",
      "1024/1024 [==============================] - ETA: 6:56 - loss: 0.1109 - categorical_accuracy: 0.66 - ETA: 6:42 - loss: 0.1075 - categorical_accuracy: 0.67 - ETA: 6:31 - loss: 0.1166 - categorical_accuracy: 0.67 - ETA: 6:23 - loss: 0.1133 - categorical_accuracy: 0.67 - ETA: 6:20 - loss: 0.1079 - categorical_accuracy: 0.66 - ETA: 6:09 - loss: 0.1070 - categorical_accuracy: 0.65 - ETA: 5:55 - loss: 0.1106 - categorical_accuracy: 0.65 - ETA: 5:40 - loss: 0.1175 - categorical_accuracy: 0.65 - ETA: 5:25 - loss: 0.1164 - categorical_accuracy: 0.64 - ETA: 5:10 - loss: 0.1161 - categorical_accuracy: 0.64 - ETA: 4:56 - loss: 0.1181 - categorical_accuracy: 0.64 - ETA: 4:41 - loss: 0.1160 - categorical_accuracy: 0.64 - ETA: 4:27 - loss: 0.1157 - categorical_accuracy: 0.65 - ETA: 4:13 - loss: 0.1149 - categorical_accuracy: 0.65 - ETA: 3:58 - loss: 0.1157 - categorical_accuracy: 0.65 - ETA: 3:44 - loss: 0.1144 - categorical_accuracy: 0.65 - ETA: 3:29 - loss: 0.1130 - categorical_accuracy: 0.65 - ETA: 3:15 - loss: 0.1117 - categorical_accuracy: 0.65 - ETA: 3:02 - loss: 0.1113 - categorical_accuracy: 0.65 - ETA: 2:48 - loss: 0.1093 - categorical_accuracy: 0.65 - ETA: 2:34 - loss: 0.1100 - categorical_accuracy: 0.64 - ETA: 2:20 - loss: 0.1086 - categorical_accuracy: 0.64 - ETA: 2:06 - loss: 0.1088 - categorical_accuracy: 0.64 - ETA: 1:52 - loss: 0.1094 - categorical_accuracy: 0.64 - ETA: 1:37 - loss: 0.1102 - categorical_accuracy: 0.64 - ETA: 1:24 - loss: 0.1111 - categorical_accuracy: 0.64 - ETA: 1:10 - loss: 0.1105 - categorical_accuracy: 0.64 - ETA: 56s - loss: 0.1105 - categorical_accuracy: 0.6442 - ETA: 42s - loss: 0.1101 - categorical_accuracy: 0.643 - ETA: 28s - loss: 0.1099 - categorical_accuracy: 0.643 - ETA: 14s - loss: 0.1093 - categorical_accuracy: 0.643 - 562s 548ms/step - loss: 0.1098 - categorical_accuracy: 0.6438 - val_loss: 0.2553 - val_categorical_accuracy: 0.6723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d12eaca828>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(new_train_words_padded, new_train_tags_padded,\n",
    "          batch_size=32,\n",
    "          epochs=4,\n",
    "          validation_data=(new_test_words_padded, new_test_tags_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = model.predict(new_test_words_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted_tags = []\n",
    "for s, s_pred in zip(test_sentences_words[:299*32], lstm_predicted):\n",
    "    tags = np.argmax(s_pred, axis=1)\n",
    "    tags = list(map(index_tag_wo_padding.get,tags))[-len(s):]\n",
    "    lstm_predicted_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo\n",
      "===============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        tim       0.76      0.49      0.59       111\n",
      "        per       0.44      0.29      0.35        93\n",
      "        org       0.31      0.08      0.12       145\n",
      "        gpe       0.35      0.74      0.47        85\n",
      "        geo       0.53      0.47      0.50       186\n",
      "        nat       0.00      0.00      0.00         3\n",
      "        art       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.48      0.39      0.40       628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('ELMo')\n",
    "print('='*15)\n",
    "print(classification_report(test_sentences_tags, lstm_predicted_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo: 0.2965222696766321\n"
     ]
    }
   ],
   "source": [
    "print('ELMo:', f1_score(test_sentences_tags[:299*32], lstm_predicted_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
