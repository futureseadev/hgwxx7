{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are predictive models that allow for a data driven exploration of nonlinear relationships and interactions among many explanatory variables in predicting a response or target variable. When the response variable is categorical (two levels), the model is a called a classification tree. Explanatory variables can be either quantitative, categorical or both. Decision trees create segmentations or subgroups in the data, by applying a series of simple rules or criteria over and over again which choose variable constellations that best predict the response (i.e. target) variable. <br/><br/>\n",
    "\n",
    "The decision tree method that we worked with during the previous session represents a powerful approach for moving beyond the consideration of linear relationships among variables into a context of prediction based on exploring how many variables can predict a particular target or response.  <br/><br/>\n",
    "\n",
    "As we have seen, an advantage of decision trees is that they're easy to interpret and visualize and can potentially uncover patterns in our data that can not be easily identified through traditional regression methods.  <br/><br/>\n",
    "\n",
    "However, we've also shown that small changes in the data can lead to different results. And we've explained, that while easy to interpret, decision trees are not very reproducible on future data. Often making them less useful, as reliable prediction models, and more suitable for exploratory data analysis and interpretation. In this session, we'll review a related machine learning method, known as Random Forests. This data mining algorithm is based on decision trees, but proceeds by growing many trees, that is a decision tree forest. In ways, directly address the problem of model reproducability.  <br/><br/>\n",
    "\n",
    "Like decision trees, Random Forests allow us to make binary splits in our data that creates segmentations or sub groups. By applying a series of simple rules or criteria over and over again, which choose variables that best predict our target variable. While decision trees proceed by searching for a split on every variable in every node, Random Forests searches for a split on only one variable in a node. The variable that has the largest association with the Target among candidate explanatory variables but only among those explanatory variables that have been randomly selected to be tested for that node. That is, First, a small subset of explanatory variables is selected at random. Next the node is split with the BEST variable among the small number of randomly selected variables. Not the best variable of all the variables, as is true when we are interested in creating only single decision tree. Once the best variable from the eligible random subset of variables is used to split the node in question. A new list of eligible explanatory variables is selected on random to split on the next node. This continues until the tree is fully grown, and Ideally there is one observation in each terminal mode. Uniquely explained by all of the decisions that came before it. With a large number of explanatory variables, the Eligible variables set will be quite different from node to node. However, Important variables will eventually make it into the tree. And Their relative success in predicting the target variable will begin to get them larger and larger numbers of \"votes\" in their favor. The growing of each tree in a random forest is not only based on subsets of explanatory variables at each node. But also based on A random subset of the sample for each tree in the forest. This process of selecting a random sample of observations is known as Bagging.  <br/><br/>\n",
    "\n",
    "Importantly, each tree is growing on a different randomly selected sample of Bagged data with the remaining Out of Bag data available to test the accuracy of each tree. For each tree, the Bagging Process selects about 60% of the original sample, while the resulting tree is tested against the remaining 40% of the sample. Thus, the randomly selected bag data and out of bag data, will be a different 60% and 40% of observations for each tree. Finally, before we start to grow our first random forest, I want to mention the most important thing to know when interrupting the results of random forests is that the trees generated are not themselves interpreted. Instead, They are used to collectively rank the importance of variables in predicting our target of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\praveen\\\\DS_Notebooks\\\\coursera\\\\machine-learning-data-analysis'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tree_addhealth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6504 entries, 0 to 6503\n",
      "Data columns (total 25 columns):\n",
      "BIO_SEX      6503 non-null float64\n",
      "HISPANIC     6481 non-null float64\n",
      "WHITE        6485 non-null float64\n",
      "BLACK        6485 non-null float64\n",
      "NAMERICAN    6485 non-null float64\n",
      "ASIAN        6485 non-null float64\n",
      "age          4837 non-null float64\n",
      "TREG1        6500 non-null float64\n",
      "ALCEVR1      6444 non-null float64\n",
      "ALCPROBS1    6504 non-null int64\n",
      "marever1     6504 non-null int64\n",
      "cocever1     6504 non-null int64\n",
      "inhever1     6504 non-null int64\n",
      "cigavail     6444 non-null float64\n",
      "DEP1         6486 non-null float64\n",
      "ESTEEM1      6483 non-null float64\n",
      "VIOL1        6454 non-null float64\n",
      "PASSIST      6504 non-null int64\n",
      "DEVIANT1     6448 non-null float64\n",
      "SCHCONN1     6368 non-null float64\n",
      "GPA1         6274 non-null float64\n",
      "EXPEL1       6486 non-null float64\n",
      "FAMCONCT     6504 non-null float64\n",
      "PARACTV      6477 non-null float64\n",
      "PARPRES      6369 non-null float64\n",
      "dtypes: float64(20), int64(5)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4575 entries, 1 to 6502\n",
      "Data columns (total 25 columns):\n",
      "BIO_SEX      4575 non-null float64\n",
      "HISPANIC     4575 non-null float64\n",
      "WHITE        4575 non-null float64\n",
      "BLACK        4575 non-null float64\n",
      "NAMERICAN    4575 non-null float64\n",
      "ASIAN        4575 non-null float64\n",
      "age          4575 non-null float64\n",
      "TREG1        4575 non-null float64\n",
      "ALCEVR1      4575 non-null float64\n",
      "ALCPROBS1    4575 non-null int64\n",
      "marever1     4575 non-null int64\n",
      "cocever1     4575 non-null int64\n",
      "inhever1     4575 non-null int64\n",
      "cigavail     4575 non-null float64\n",
      "DEP1         4575 non-null float64\n",
      "ESTEEM1      4575 non-null float64\n",
      "VIOL1        4575 non-null float64\n",
      "PASSIST      4575 non-null int64\n",
      "DEVIANT1     4575 non-null float64\n",
      "SCHCONN1     4575 non-null float64\n",
      "GPA1         4575 non-null float64\n",
      "EXPEL1       4575 non-null float64\n",
      "FAMCONCT     4575 non-null float64\n",
      "PARACTV      4575 non-null float64\n",
      "PARPRES      4575 non-null float64\n",
      "dtypes: float64(20), int64(5)\n",
      "memory usage: 929.3 KB\n"
     ]
    }
   ],
   "source": [
    "data_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIO_SEX      float64\n",
       "HISPANIC     float64\n",
       "WHITE        float64\n",
       "BLACK        float64\n",
       "NAMERICAN    float64\n",
       "ASIAN        float64\n",
       "age          float64\n",
       "TREG1        float64\n",
       "ALCEVR1      float64\n",
       "ALCPROBS1      int64\n",
       "marever1       int64\n",
       "cocever1       int64\n",
       "inhever1       int64\n",
       "cigavail     float64\n",
       "DEP1         float64\n",
       "ESTEEM1      float64\n",
       "VIOL1        float64\n",
       "PASSIST        int64\n",
       "DEVIANT1     float64\n",
       "SCHCONN1     float64\n",
       "GPA1         float64\n",
       "EXPEL1       float64\n",
       "FAMCONCT     float64\n",
       "PARACTV      float64\n",
       "PARPRES      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIO_SEX</th>\n",
       "      <th>HISPANIC</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>BLACK</th>\n",
       "      <th>NAMERICAN</th>\n",
       "      <th>ASIAN</th>\n",
       "      <th>age</th>\n",
       "      <th>TREG1</th>\n",
       "      <th>ALCEVR1</th>\n",
       "      <th>ALCPROBS1</th>\n",
       "      <th>...</th>\n",
       "      <th>ESTEEM1</th>\n",
       "      <th>VIOL1</th>\n",
       "      <th>PASSIST</th>\n",
       "      <th>DEVIANT1</th>\n",
       "      <th>SCHCONN1</th>\n",
       "      <th>GPA1</th>\n",
       "      <th>EXPEL1</th>\n",
       "      <th>FAMCONCT</th>\n",
       "      <th>PARACTV</th>\n",
       "      <th>PARPRES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "      <td>4575.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.521093</td>\n",
       "      <td>0.111038</td>\n",
       "      <td>0.683279</td>\n",
       "      <td>0.236066</td>\n",
       "      <td>0.036284</td>\n",
       "      <td>0.040437</td>\n",
       "      <td>16.493052</td>\n",
       "      <td>0.176393</td>\n",
       "      <td>0.527432</td>\n",
       "      <td>0.369180</td>\n",
       "      <td>...</td>\n",
       "      <td>40.952131</td>\n",
       "      <td>1.618579</td>\n",
       "      <td>0.102514</td>\n",
       "      <td>2.645027</td>\n",
       "      <td>28.360656</td>\n",
       "      <td>2.815647</td>\n",
       "      <td>0.040219</td>\n",
       "      <td>22.570557</td>\n",
       "      <td>6.290710</td>\n",
       "      <td>13.398033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499609</td>\n",
       "      <td>0.314214</td>\n",
       "      <td>0.465249</td>\n",
       "      <td>0.424709</td>\n",
       "      <td>0.187017</td>\n",
       "      <td>0.197004</td>\n",
       "      <td>1.552174</td>\n",
       "      <td>0.381196</td>\n",
       "      <td>0.499302</td>\n",
       "      <td>0.894947</td>\n",
       "      <td>...</td>\n",
       "      <td>5.381439</td>\n",
       "      <td>2.593230</td>\n",
       "      <td>0.303356</td>\n",
       "      <td>3.520554</td>\n",
       "      <td>5.156385</td>\n",
       "      <td>0.770167</td>\n",
       "      <td>0.196493</td>\n",
       "      <td>2.614754</td>\n",
       "      <td>3.360219</td>\n",
       "      <td>2.085837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.676712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.254795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.509589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.679452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.300000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.512329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           BIO_SEX     HISPANIC        WHITE        BLACK    NAMERICAN  \\\n",
       "count  4575.000000  4575.000000  4575.000000  4575.000000  4575.000000   \n",
       "mean      1.521093     0.111038     0.683279     0.236066     0.036284   \n",
       "std       0.499609     0.314214     0.465249     0.424709     0.187017   \n",
       "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       2.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       2.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       2.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             ASIAN          age        TREG1      ALCEVR1    ALCPROBS1  \\\n",
       "count  4575.000000  4575.000000  4575.000000  4575.000000  4575.000000   \n",
       "mean      0.040437    16.493052     0.176393     0.527432     0.369180   \n",
       "std       0.197004     1.552174     0.381196     0.499302     0.894947   \n",
       "min       0.000000    12.676712     0.000000     0.000000     0.000000   \n",
       "25%       0.000000    15.254795     0.000000     0.000000     0.000000   \n",
       "50%       0.000000    16.509589     0.000000     1.000000     0.000000   \n",
       "75%       0.000000    17.679452     0.000000     1.000000     0.000000   \n",
       "max       1.000000    21.512329     1.000000     1.000000     6.000000   \n",
       "\n",
       "          ...           ESTEEM1        VIOL1      PASSIST     DEVIANT1  \\\n",
       "count     ...       4575.000000  4575.000000  4575.000000  4575.000000   \n",
       "mean      ...         40.952131     1.618579     0.102514     2.645027   \n",
       "std       ...          5.381439     2.593230     0.303356     3.520554   \n",
       "min       ...         18.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...         38.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...         40.000000     0.000000     0.000000     1.000000   \n",
       "75%       ...         45.000000     2.000000     0.000000     4.000000   \n",
       "max       ...         50.000000    19.000000     1.000000    27.000000   \n",
       "\n",
       "          SCHCONN1         GPA1       EXPEL1     FAMCONCT      PARACTV  \\\n",
       "count  4575.000000  4575.000000  4575.000000  4575.000000  4575.000000   \n",
       "mean     28.360656     2.815647     0.040219    22.570557     6.290710   \n",
       "std       5.156385     0.770167     0.196493     2.614754     3.360219   \n",
       "min       6.000000     1.000000     0.000000     6.300000     0.000000   \n",
       "25%      25.000000     2.250000     0.000000    21.700000     4.000000   \n",
       "50%      29.000000     2.750000     0.000000    23.700000     6.000000   \n",
       "75%      32.000000     3.500000     0.000000    24.300000     9.000000   \n",
       "max      38.000000     4.000000     1.000000    25.000000    18.000000   \n",
       "\n",
       "           PARPRES  \n",
       "count  4575.000000  \n",
       "mean     13.398033  \n",
       "std       2.085837  \n",
       "min       3.000000  \n",
       "25%      12.000000  \n",
       "50%      14.000000  \n",
       "75%      15.000000  \n",
       "max      15.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = data_clean[['BIO_SEX','HISPANIC','WHITE','BLACK','NAMERICAN','ASIAN',\n",
    "'age','ALCEVR1','ALCPROBS1','marever1','cocever1','inhever1','cigavail','DEP1',\n",
    "'ESTEEM1','VIOL1','PASSIST','DEVIANT1','SCHCONN1','GPA1','EXPEL1','FAMCONCT','PARACTV',\n",
    "'PARPRES']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIO_SEX</th>\n",
       "      <th>HISPANIC</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>BLACK</th>\n",
       "      <th>NAMERICAN</th>\n",
       "      <th>ASIAN</th>\n",
       "      <th>age</th>\n",
       "      <th>ALCEVR1</th>\n",
       "      <th>ALCPROBS1</th>\n",
       "      <th>marever1</th>\n",
       "      <th>...</th>\n",
       "      <th>ESTEEM1</th>\n",
       "      <th>VIOL1</th>\n",
       "      <th>PASSIST</th>\n",
       "      <th>DEVIANT1</th>\n",
       "      <th>SCHCONN1</th>\n",
       "      <th>GPA1</th>\n",
       "      <th>EXPEL1</th>\n",
       "      <th>FAMCONCT</th>\n",
       "      <th>PARACTV</th>\n",
       "      <th>PARPRES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.427397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.430137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.509589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.676712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.178082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BIO_SEX  HISPANIC  WHITE  BLACK  NAMERICAN  ASIAN        age  ALCEVR1  \\\n",
       "1      2.0       0.0    0.0    1.0        0.0    0.0  19.427397      1.0   \n",
       "3      1.0       0.0    0.0    1.0        0.0    0.0  20.430137      0.0   \n",
       "5      1.0       0.0    0.0    1.0        0.0    0.0  14.509589      0.0   \n",
       "6      1.0       0.0    0.0    1.0        0.0    0.0  13.676712      0.0   \n",
       "7      1.0       0.0    1.0    0.0        0.0    0.0  15.178082      1.0   \n",
       "\n",
       "   ALCPROBS1  marever1   ...     ESTEEM1  VIOL1  PASSIST  DEVIANT1  SCHCONN1  \\\n",
       "1          1         0   ...        35.0    1.0        0       5.0      22.0   \n",
       "3          0         1   ...        47.0    4.0        1       4.0      19.0   \n",
       "5          0         0   ...        41.0    3.0        0       0.0      27.0   \n",
       "6          0         0   ...        42.0    5.0        0       7.0      18.0   \n",
       "7          0         1   ...        40.0    8.0        1       6.0      20.0   \n",
       "\n",
       "       GPA1  EXPEL1  FAMCONCT  PARACTV  PARPRES  \n",
       "1  2.333333     0.0      23.3      9.0     15.0  \n",
       "3  2.000000     0.0      18.7      6.0     14.0  \n",
       "5  2.666667     0.0      23.7      3.0     13.0  \n",
       "6  2.500000     0.0      24.7      6.0     13.0  \n",
       "7  1.500000     0.0      22.3     10.0     14.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = data_clean.TREG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1.0\n",
       "3    1.0\n",
       "5    0.0\n",
       "6    0.0\n",
       "7    1.0\n",
       "Name: TREG1, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60:40 split train:test\n",
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, targets, test_size=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2745, 24), (1830, 24))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train.shape, pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2745,), (1830,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_train.shape, tar_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model on training data\n",
    "classifier = RandomForestClassifier(n_estimators=25)\n",
    "classifier = classifier.fit(pred_train,tar_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1426,   71],\n",
       "       [ 217,  116]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(tar_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the confusion matrix, we see the true negatives and true positives on the diagonal. And the 203 and the 87 represent the false negatives and false positives, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8426229508196721"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(tar_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the overall accuracy for the forest is 0.84. So 84% of the individuals were classified correctly, as regular smokers, or not regular smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(pred_train,tar_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we don't interpret individual trees in a random forest, the most helpful information to be gotten from a forest is arguably the measured importance for each explanatory variable. Also called the features. Based on how many votes or splits each has produced in the 25 tree ensemble. To generate importance scores, we initialize the extra tree classifier, and then fit a model. Finally, we ask Python to print the feature importance scores calculated from the forest of trees that we've grown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03039088 0.01632801 0.02414836 0.01907534 0.01072417 0.00616354\n",
      " 0.06055683 0.04455143 0.04533399 0.09638234 0.01609588 0.01656267\n",
      " 0.02968987 0.06105916 0.05077503 0.05049175 0.01659474 0.08531605\n",
      " 0.06970171 0.06622569 0.01011674 0.06253634 0.06235289 0.0488266 ]\n"
     ]
    }
   ],
   "source": [
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are listed in the order they've been named earlier in the code. Starting with gender, called BIO_SEX, and ending with parental presence. As we can see the variables with the highest important score at 0.13 is marijuana use. And the variable with the lowest important score is Asian ethnicity at .004. As you will recall, the correct classification rate for the random forest was 84%. So were 25 trees actually needed to get this correct rate of classification? To determine what growing larger number of trees has brought us in terms of correct classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRunning a different number of trees and see the effect\\n of that on the accuracy of the prediction\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Running a different number of trees and see the effect\n",
    " of that on the accuracy of the prediction\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = range(25)\n",
    "accuracy = np.zeros(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(range(0, 25),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use code that builds for us different numbers of trees, from one to 25, and provides the correct classification rate for each. This code will build for us random forest classifier from one to 25, and then finding the accuracy score for each of those trees from one to 25, and storing it in an array. This will give me 25 different accuracy values. And we'll plot them as the number of trees increase. As you can see, with only one tree the accuracy is about 83%, and it climbs to only about 84% with successive trees that are grown giving us some confidence that it may be perfectly appropriate to interpret a single decision tree for this data. Given that it's accuracy is quite near that of successive trees in the forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(trees)):\n",
    "   classifier    = RandomForestClassifier(n_estimators = idx + 1)\n",
    "   classifier    = classifier.fit(pred_train, tar_train)\n",
    "   predictions   = classifier.predict(pred_test)\n",
    "   accuracy[idx] = sklearn.metrics.accuracy_score(tar_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x218c6910e80>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218c686c2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.cla()\n",
    "plt.plot(trees, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "To summarize, like decision trees, random forests are a type of data mining algorithm that can select from among a large number of variables. Those that are most important in determining the target or response variable to be explained. <br/>\n",
    "\n",
    "Also light decision trees. The target variable in a random forest can be categorical or quantitative. And the group of explanatory variables or features can be categorical and quantitative in any combination. Unlike decision trees however, the results of random forests often generalize well to new data. Since the strongest signals are able to emerge through the growing of many trees. Further, small changes in the data do not impact the results of a random forest. In my opinion, the main weakness of random forests is simply that the results are less satisfying, since no trees are actually interpreted. Instead, the forest of trees is used to rank the importance of variables in predicting the target. Thus we get a sense of the most important predictive variables but not necessarily their relationships to one another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest analysis was performed to evaluate the importance of a series of explanatory variables in predicting a binary, categorical response variable. The following explanatory variables were included as possible contributors to a random forest evaluating regular smoking (my response variable), age, gender, (race/ethnicity) Hispanic, White, Black, Native American and Asian. Alcohol use, marijuana use, cocaine use, inhalant use, availability of cigarettes in the home, whether or not either parent was on public assistance, any experience with being expelled from school, alcohol problems, deviance, violence, depression, self-esteem, parental presence, parental activities, family connectedness, school connectedness and grade point average.\n",
    "\n",
    "The explanatory variables with the highest relative importance scores were marijuana use, White ethnicity, deviance and grade point average. The accuracy of the random forest was 84%, with the subsequent growing of multiple trees rather than a single tree, adding little to the overall accuracy of the model, and suggesting that interpretation of a single decision tree may be appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
